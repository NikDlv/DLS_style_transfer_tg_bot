{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "621281e5",
      "metadata": {},
      "source": [
        "Пожалуйста, перед началом работы создайте файл `config.json` с Вашим API ключом от телеграм бота:\n",
        "```json\n",
        "{\n",
        "    \"telegram_token\": \"YOUR_API_KEY\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Fe1ZXvVeRyq0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe1ZXvVeRyq0",
        "outputId": "dd970cce-5662-47ea-def5-69dc29263eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.7/708.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu10).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu9.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision --quiet\n",
        "!pip install python-telegram-bot --quiet\n",
        "!apt install -y libjpeg-dev zlib1g-dev\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e19d308",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1fddd0ca",
      "metadata": {
        "id": "1fddd0ca"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import gdown\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from telegram import Update, ReplyKeyboardMarkup\n",
        "from telegram.ext import (\n",
        "    ApplicationBuilder,\n",
        "    CommandHandler,\n",
        "    MessageHandler,\n",
        "    ContextTypes,\n",
        "    filters\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "mdoMSvYdTCpn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "mdoMSvYdTCpn",
        "outputId": "1b8aec0b-e473-4277-ffa8-9c2d9e871219"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1iCbjhPnJ2sJqGzcjU2L5ZJOZZt7JKXyi\n",
            "From (redirected): https://drive.google.com/uc?id=1iCbjhPnJ2sJqGzcjU2L5ZJOZZt7JKXyi&confirm=t&uuid=d38f9e8c-d79e-4588-bab7-7ed98de3a181\n",
            "To: /content/model_weights.zip\n",
            "100%|██████████| 140M/140M [00:01<00:00, 94.7MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'model_weights.zip'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = 'https://drive.google.com/uc?id=1iCbjhPnJ2sJqGzcjU2L5ZJOZZt7JKXyi'\n",
        "output = 'model_weights.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9XtOk2TUU8t0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XtOk2TUU8t0",
        "outputId": "5f94db7c-1b77-4d4d-9517-dd16e4fac87b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  model_weights.zip\n",
            "   creating: model_weights/\n",
            "  inflating: model_weights/decoder.pth  \n",
            "  inflating: model_weights/decoder_van_gogh.pth  \n",
            "  inflating: model_weights/decoder_picasso.pth  \n",
            "  inflating: model_weights/decoder_monet.pth  \n",
            "  inflating: model_weights/vgg_normalised.pth  \n",
            "  inflating: model_weights/decoder_trained.pth  \n"
          ]
        }
      ],
      "source": [
        "!unzip model_weights.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "11379352",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "11379352",
        "outputId": "0d3b46d1-9026-47a5-cc28-f3673dad3a1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TdpdEmBiA267KclBplEvOczgX4HGRbFj\n",
            "To: /content/test_images.zip\n",
            "100%|██████████| 1.92M/1.92M [00:00<00:00, 30.1MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test_images.zip'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = 'https://drive.google.com/uc?id=1TdpdEmBiA267KclBplEvOczgX4HGRbFj'\n",
        "output = 'test_images.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "40a488c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40a488c7",
        "outputId": "78d41aee-556f-4221-f5e9-ae24e81c33cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  test_images.zip\n",
            "   creating: test_images/\n",
            "   creating: test_images/content/\n",
            "  inflating: test_images/content/dancing.jpg  \n",
            "  inflating: test_images/bot_interface.png  \n",
            "   creating: test_images/style/\n",
            "  inflating: test_images/style/picasso.jpg  \n",
            "  inflating: test_images/style/van_gogh.jpg  \n",
            "  inflating: test_images/style/monet.jpg  \n",
            "  inflating: test_images/style/style.jpg  \n",
            "  inflating: test_images/bot_transfer.png  \n",
            "  inflating: test_images/bot_van_gogh.png  \n"
          ]
        }
      ],
      "source": [
        "!unzip test_images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cc36140e",
      "metadata": {
        "id": "cc36140e"
      },
      "outputs": [],
      "source": [
        "# image io\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(512),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "def load_image(image_bytes):\n",
        "    image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
        "    return transform(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "18cece9d",
      "metadata": {
        "id": "18cece9d"
      },
      "outputs": [],
      "source": [
        "# adain_utils\n",
        "\n",
        "def calc_mean_std(feat, eps=1e-5):\n",
        "    \"\"\"\n",
        "    Calculate the channel-wise mean and standard deviation of a feature tensor.\n",
        "\n",
        "    Args:\n",
        "        feat (Tensor): Input tensor\n",
        "        eps (float): Small constant to avoid division by zero.\n",
        "\n",
        "    Returns:\n",
        "        Mean and standard deviation tensors.\n",
        "    \"\"\"\n",
        "    size = feat.size()\n",
        "    assert (len(size) == 4)\n",
        "    N, C = size[:2]\n",
        "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
        "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
        "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
        "    return feat_mean, feat_std\n",
        "\n",
        "\n",
        "def adaptive_instance_normalization(content_feat, style_feat):\n",
        "    \"\"\"\n",
        "    Apply Adaptive Instance Normalization to content features using style features.\n",
        "\n",
        "    Args:\n",
        "        content_feat (Tensor): Content features\n",
        "        style_feat (Tensor): Style features\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Stylized feature tensor of the same shape as content_feat.\n",
        "    \"\"\"\n",
        "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
        "    size = content_feat.size()\n",
        "    style_mean, style_std = calc_mean_std(style_feat)\n",
        "    content_mean, content_std = calc_mean_std(content_feat)\n",
        "\n",
        "    normalized_feat = (content_feat - content_mean.expand(\n",
        "        size)) / content_std.expand(size)\n",
        "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)\n",
        "\n",
        "\n",
        "def _calc_feat_flatten_mean_std(feat):\n",
        "    \"\"\"\n",
        "    Flatten 3D feature map and compute per-channel mean and std.\n",
        "    \"\"\"\n",
        "    assert (feat.size()[0] == 3)\n",
        "    assert (isinstance(feat, torch.FloatTensor))\n",
        "    feat_flatten = feat.view(3, -1)\n",
        "    mean = feat_flatten.mean(dim=-1, keepdim=True)\n",
        "    std = feat_flatten.std(dim=-1, keepdim=True)\n",
        "    return feat_flatten, mean, std\n",
        "\n",
        "\n",
        "def _mat_sqrt(x):\n",
        "    \"\"\"\n",
        "    Compute the matrix square root using SVD.\n",
        "    \"\"\"\n",
        "    U, D, V = torch.svd(x)\n",
        "    return torch.mm(torch.mm(U, D.pow(0.5).diag()), V.t())\n",
        "\n",
        "\n",
        "def coral(source, target):\n",
        "    \"\"\"\n",
        "    Perform CORAL (Correlation Alignment) to match the color distribution of the source to the target.\n",
        "    \"\"\"\n",
        "\n",
        "    source_f, source_f_mean, source_f_std = _calc_feat_flatten_mean_std(source)\n",
        "    source_f_norm = (source_f - source_f_mean.expand_as(\n",
        "        source_f)) / source_f_std.expand_as(source_f)\n",
        "    source_f_cov_eye = \\\n",
        "        torch.mm(source_f_norm, source_f_norm.t()) + torch.eye(3)\n",
        "\n",
        "    target_f, target_f_mean, target_f_std = _calc_feat_flatten_mean_std(target)\n",
        "    target_f_norm = (target_f - target_f_mean.expand_as(\n",
        "        target_f)) / target_f_std.expand_as(target_f)\n",
        "    target_f_cov_eye = \\\n",
        "        torch.mm(target_f_norm, target_f_norm.t()) + torch.eye(3)\n",
        "\n",
        "    source_f_norm_transfer = torch.mm(\n",
        "        _mat_sqrt(target_f_cov_eye),\n",
        "        torch.mm(torch.inverse(_mat_sqrt(source_f_cov_eye)),\n",
        "                 source_f_norm)\n",
        "    )\n",
        "\n",
        "    source_f_transfer = (source_f_norm_transfer *\n",
        "                         target_f_std.expand_as(source_f_norm) +\n",
        "                         target_f_mean.expand_as(source_f_norm))\n",
        "\n",
        "    return source_f_transfer.view(source.size())\n",
        "\n",
        "\n",
        "def style_transfer(vgg, decoder, content, style, alpha):\n",
        "    \"\"\"\n",
        "    Perform neural style transfer using AdaIN.\n",
        "    \"\"\"\n",
        "    assert (0.0 <= alpha <= 1.0)\n",
        "    content_f = vgg(content)\n",
        "    style_f = vgg(style)\n",
        "    feat = adaptive_instance_normalization(content_f, style_f)\n",
        "    feat = feat * alpha + content_f * (1 - alpha)\n",
        "    return decoder(feat)\n",
        "\n",
        "\n",
        "def process_images(net, content_bytes, style_bytes, alpha, preserve_colors=False):\n",
        "    \"\"\"Perform style transfer on image bytes\"\"\"\n",
        "    content = load_image(content_bytes)\n",
        "    style = load_image(style_bytes)\n",
        "\n",
        "    # Apply color preservation if needed\n",
        "    if preserve_colors:\n",
        "        style = coral(style, content)\n",
        "\n",
        "    # Move to device and add batch dimension\n",
        "    device = next(net.parameters()).device\n",
        "    content = content.to(device).unsqueeze(0)\n",
        "    style = style.to(device).unsqueeze(0)\n",
        "\n",
        "    # Perform style transfer\n",
        "    with torch.no_grad():\n",
        "        output = style_transfer(\n",
        "            net.encode,\n",
        "            net.decoder,\n",
        "            content,\n",
        "            style,\n",
        "            alpha=alpha\n",
        "        )\n",
        "\n",
        "    # Convert to PIL image\n",
        "    output = output.clamp(0, 1)\n",
        "    return transforms.ToPILImage()(output.squeeze(0).cpu())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "26686b28",
      "metadata": {
        "id": "26686b28"
      },
      "outputs": [],
      "source": [
        "# adain_net\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder network used to reconstruct an image from AdaIN features.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(512, 256, (3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(256, 256, (3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(256, 256, (3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(256, 256, (3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(256, 128, (3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(128, 128, (3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(128, 64, (3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(64, 64, (3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(64, 3, (3, 3)),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified VGG-19 encoder used to extract content and style features.\n",
        "    Includes convolutional layers up to relu4_1. Extra layers are present but not used.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(VGG, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 3, (1, 1)),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(3, 64, (3, 3)),\n",
        "            nn.ReLU(),  # relu1-1\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(64, 64, (3, 3)),\n",
        "            nn.ReLU(),  # relu1-2\n",
        "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(64, 128, (3, 3)),\n",
        "            nn.ReLU(),  # relu2-1\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(128, 128, (3, 3)),\n",
        "            nn.ReLU(),  # relu2-2\n",
        "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(128, 256, (3, 3)),\n",
        "            nn.ReLU(),  # relu3-1\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(256, 256, (3, 3)),\n",
        "            nn.ReLU(),  # relu3-2\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(256, 256, (3, 3)),\n",
        "            nn.ReLU(),  # relu3-3\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(256, 256, (3, 3)),\n",
        "            nn.ReLU(),  # relu3-4\n",
        "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(256, 512, (3, 3)),\n",
        "            nn.ReLU(),  # relu4-1, this is the last layer used\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(512, 512, (3, 3)),\n",
        "            nn.ReLU(),  # relu4-2\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(512, 512, (3, 3)),\n",
        "            nn.ReLU(),  # relu4-3\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(512, 512, (3, 3)),\n",
        "            nn.ReLU(),  # relu4-4\n",
        "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(512, 512, (3, 3)),\n",
        "            nn.ReLU(),  # relu5-1\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(512, 512, (3, 3)),\n",
        "            nn.ReLU(),  # relu5-2\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(512, 512, (3, 3)),\n",
        "            nn.ReLU(),  # relu5-3\n",
        "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(512, 512, (3, 3)),\n",
        "            nn.ReLU()  # relu5-4\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    Style transfer network combining a fixed VGG encoder and a trainable decoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Net, self).__init__()\n",
        "        enc_layers = list(encoder.children())\n",
        "        self.enc_1 = nn.Sequential(*enc_layers[:4])  # input -> relu1_1\n",
        "        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n",
        "        self.enc_3 = nn.Sequential(*enc_layers[11:18])  # relu2_1 -> relu3_1\n",
        "        self.enc_4 = nn.Sequential(*enc_layers[18:31])  # relu3_1 -> relu4_1\n",
        "        self.decoder = decoder\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "        # fix the encoder\n",
        "        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4']:\n",
        "            for param in getattr(self, name).parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    # extract relu1_1, relu2_1, relu3_1, relu4_1 from input image\n",
        "    def encode_with_intermediate(self, input):\n",
        "        \"\"\"\n",
        "        Extract intermediate features (relu1_1 to relu4_1) from the input image.\n",
        "\n",
        "        Returns:\n",
        "            List of feature maps at different VGG depths.\n",
        "        \"\"\"\n",
        "        results = [input]\n",
        "        for i in range(4):\n",
        "            func = getattr(self, 'enc_{:d}'.format(i + 1))\n",
        "            results.append(func(results[-1]))\n",
        "        return results[1:]\n",
        "\n",
        "    # extract relu4_1 from input image\n",
        "    def encode(self, input):\n",
        "        \"\"\"\n",
        "        Encode input image to relu4_1 feature map using the VGG encoder.\n",
        "\n",
        "        Returns:\n",
        "            Feature map after relu4_1.\n",
        "        \"\"\"\n",
        "        for i in range(4):\n",
        "            input = getattr(self, 'enc_{:d}'.format(i + 1))(input)\n",
        "        return input\n",
        "\n",
        "    def calc_content_loss(self, input, target):\n",
        "        \"\"\"\n",
        "        Compute content loss as MSE between generated and target feature maps.\n",
        "\n",
        "        Returns:\n",
        "            Scalar content loss.\n",
        "        \"\"\"\n",
        "        assert (input.size() == target.size())\n",
        "        assert (target.requires_grad is False)\n",
        "        return self.mse_loss(input, target)\n",
        "\n",
        "    def calc_style_loss(self, input, target):\n",
        "        \"\"\"\n",
        "        Compute style loss as the sum of MSE between mean and std of input and target.\n",
        "\n",
        "        Returns:\n",
        "            Scalar style loss.\n",
        "        \"\"\"\n",
        "        assert (input.size() == target.size())\n",
        "        assert (target.requires_grad is False)\n",
        "        input_mean, input_std = calc_mean_std(input)\n",
        "        target_mean, target_std = calc_mean_std(target)\n",
        "        return (self.mse_loss(input_mean, target_mean) +\n",
        "                self.mse_loss(input_std, target_std))\n",
        "\n",
        "    def forward(self, content, style, alpha=1.0):\n",
        "        \"\"\"\n",
        "        Perform forward pass of the style transfer network.\n",
        "\n",
        "        Args:\n",
        "            content: content image tensor\n",
        "            style: style image tensor\n",
        "            alpha: interpolation factor between content and style features (0 to 1)\n",
        "\n",
        "        Returns:\n",
        "            Content loss and total style loss\n",
        "        \"\"\"\n",
        "        assert 0 <= alpha <= 1\n",
        "        style_feats = self.encode_with_intermediate(style)\n",
        "        content_feat = self.encode(content)\n",
        "        t = adaptive_instance_normalization(content_feat, style_feats[-1])\n",
        "        t = alpha * t + (1 - alpha) * content_feat\n",
        "\n",
        "        g_t = self.decoder(t)\n",
        "        g_t_feats = self.encode_with_intermediate(g_t)\n",
        "\n",
        "        loss_c = self.calc_content_loss(g_t_feats[-1], t)\n",
        "        loss_s = self.calc_style_loss(g_t_feats[0], style_feats[0])\n",
        "        for i in range(1, 4):\n",
        "            loss_s += self.calc_style_loss(g_t_feats[i], style_feats[i])\n",
        "        return loss_c, loss_s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "defeea1e",
      "metadata": {
        "id": "defeea1e"
      },
      "outputs": [],
      "source": [
        "def init_model():\n",
        "    \"\"\"Initialize and load style transfer model\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using GPU:\", torch.cuda.is_available())\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n",
        "    decoder = Decoder()\n",
        "    vgg = VGG()\n",
        "\n",
        "    # Load weights\n",
        "    decoder.model.load_state_dict(torch.load('model_weights/decoder.pth', map_location=device))\n",
        "    vgg.model.load_state_dict(torch.load('model_weights/vgg_normalised.pth', map_location=device))\n",
        "\n",
        "    # Configure models\n",
        "    vgg = nn.Sequential(*list(vgg.model.children())[:31])\n",
        "    vgg.to(device).eval()\n",
        "    decoder.to(device).eval()\n",
        "\n",
        "    decoder_picasso = Decoder()\n",
        "    decoder_van_gogh = Decoder()\n",
        "    decoder_monet = Decoder()\n",
        "\n",
        "    # Load weights for fine-tuned models\n",
        "    decoder_picasso.load_state_dict(torch.load('model_weights/decoder_picasso.pth', map_location=device))\n",
        "    decoder_van_gogh.load_state_dict(torch.load('model_weights/decoder_van_gogh.pth', map_location=device))\n",
        "    decoder_monet.load_state_dict(torch.load('model_weights/decoder_monet.pth', map_location=device))\n",
        "\n",
        "    decoder_picasso.to(device).eval()\n",
        "    decoder_van_gogh.to(device).eval()\n",
        "    decoder_monet.to(device).eval()\n",
        "\n",
        "    return (Net(vgg, decoder).to(device).eval(), Net(vgg, decoder_picasso).to(device).eval(),\n",
        "            Net(vgg, decoder_van_gogh).to(device).eval(), Net(vgg, decoder_monet).to(device).eval())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f35636",
      "metadata": {
        "id": "64f35636"
      },
      "outputs": [],
      "source": [
        "USER_DATA_FILE = \"user_data/user_preferences.json\"\n",
        "USER_DATA_DIR = 'user_data'\n",
        "\n",
        "\n",
        "def load_user_data():\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(USER_DATA_FILE), exist_ok=True)\n",
        "    \n",
        "    # Create file with empty dict if it doesn't exist\n",
        "    if not os.path.exists(USER_DATA_FILE):\n",
        "        with open(USER_DATA_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({}, f)\n",
        "    \n",
        "    # Read and return the data\n",
        "    with open(USER_DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def save_user_data(data):\n",
        "    with open(USER_DATA_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "\n",
        "def get_user_settings(user_data, user_id):\n",
        "    return user_data.get(str(user_id), {})\n",
        "\n",
        "\n",
        "def update_user_settings(user_data, user_id, updates: dict):\n",
        "    uid = str(user_id)\n",
        "    if uid not in user_data:\n",
        "        user_data[uid] = {}\n",
        "    user_data[uid].update(updates)\n",
        "    save_user_data(user_data)\n",
        "\n",
        "\n",
        "def save_user_images(user_id: str, content: bytes, style: bytes, output: BytesIO):\n",
        "    \"\"\"\n",
        "    Saves content, style, and output images in a user-specific timestamped folder.\n",
        "    \"\"\"\n",
        "    # Create user directory and timestamped subfolder\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    user_dir = os.path.join(USER_DATA_DIR, user_id, f\"result_{timestamp}\")\n",
        "    os.makedirs(user_dir, exist_ok=True)\n",
        "\n",
        "    # Save content image\n",
        "    with open(os.path.join(user_dir, \"content.jpg\"), \"wb\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "    # Save style image\n",
        "    with open(os.path.join(user_dir, \"style.jpg\"), \"wb\") as f:\n",
        "        f.write(style)\n",
        "\n",
        "    # Save output image\n",
        "    output_path = os.path.join(user_dir, \"output.jpg\")\n",
        "    with open(output_path, \"wb\") as f:\n",
        "        f.write(output.getbuffer())\n",
        "\n",
        "    print(f\"Saved images for user {user_id} in {user_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6d84bd2f",
      "metadata": {
        "id": "6d84bd2f"
      },
      "outputs": [],
      "source": [
        "MESSAGES = {\n",
        "    \"en\": {\n",
        "        \"welcome\": \"\"\"\n",
        "👋 Welcome to the Fast Style Transfer Bot!\n",
        "\n",
        "✨ Choose one of the image generation options:\n",
        "\n",
        "1️⃣  **Style Transfer** 🎨\n",
        "Apply a style from any image to your content photo while keeping the original composition.\n",
        "\n",
        "2️⃣  **Color-Preserving** 🌈\n",
        "Keep your original photo's colors while applying the style's textures and patterns.\n",
        "\n",
        "3️⃣  **Select a Style** 🖼️\n",
        "Select a famous painting style (Van Gogh, Monet, Picasso) and apply it to your photo.\n",
        "\n",
        "⚙️ You can also adjust the strength of the style transfer using the **\"Set alpha\"** command.\n",
        "Choose a value between 0 and 1 — higher values mean stronger stylization.\n",
        "\n",
        "🌐 To change the bot's language, use the **\"Language\"** command and select your preferred language.\n",
        "\"\"\",\n",
        "        \"standard_instructions\": \"\"\"\n",
        "📌 Please follow these steps:\n",
        "\n",
        "1️⃣ Send the *content* image first\n",
        "2️⃣ Then send the *style* image\n",
        "\n",
        "💡 You can also send both images in one message!\n",
        "\"\"\",\n",
        "        \"content_received\": \"✅ Content image received! Now send the style image.\",\n",
        "        \"style_received\": \"✅ Style image received! Starting style transfer...\",\n",
        "        \"processing\": \"🔄 Performing style transfer...\",\n",
        "        \"success\": \"🎨 Style transfer complete!\",\n",
        "        \"error\": \"⚠️ An error occurred during processing. Please try again.\",\n",
        "        \"mode_not_selected\": \"❌ Please first select a style transfer mode from the menu.\",\n",
        "        \"invalid_option\": \"❌ Please choose one of the available options.\",\n",
        "        \"alpha_prompt\": \"🔧 Please enter a value for alpha (between 0 and 1):\",\n",
        "        \"alpha_set\": \"✅ Alpha set to {alpha}.\",\n",
        "        \"alpha_invalid\": \"❌ Invalid value. Please enter a number between 0 and 1.\",\n",
        "        \"language_prompt\": \"🌍 Please choose your language:\",\n",
        "        \"language_set\": \"✅ Language set to English.\",\n",
        "        \"language_invalid\": \"❌ Invalid choice, please select a language from the keyboard.\",\n",
        "        \"choose_style_prompt\": \"🖼️ Please select a style from the list below:\",\n",
        "        \"style_selected\": \"🎨 Style {style} selected! Now please send the content image.\",\n",
        "        \"choose_option\": \"📋 Please select an option from the menu.\"\n",
        "    },\n",
        "\n",
        "    \"ru\": {\n",
        "        \"welcome\": \"\"\"\n",
        "👋 Добро пожаловать в бота для переноса стиля!\n",
        "\n",
        "✨ Выберите один из вариантов:\n",
        "\n",
        "1️⃣  **Перенос стиля** 🎨\n",
        "Примените стиль из любого изображения к вашему фото, сохранив оригинальную композицию.\n",
        "\n",
        "2️⃣  **Сохранение цветов** 🌈\n",
        "Сохраните оригинальные цвета вашего фото, применяя только текстуры и паттерны стиля.\n",
        "\n",
        "3️⃣  **Выбрать готовый стиль** 🖼️\n",
        "Выберите стиль известного художника (Ван Гог, Моне, Пикассо) и примените его к своей фотографии.\n",
        "\n",
        "⚙️ Вы также можете настроить силу переноса стиля с помощью команды **\"Установить alpha\"**.\n",
        "Укажите значение от 0 до 1 — чем больше значение, тем сильнее эффект стилизации.\n",
        "\n",
        "🌐 Чтобы изменить язык бота, используйте команду **\"Язык\"** и выберите предпочитаемый язык.\n",
        "\"\"\",\n",
        "        \"standard_instructions\": \"\"\"\n",
        "📌 Инструкция:\n",
        "\n",
        "1️⃣ Сначала отправьте *контентное* изображение\n",
        "2️⃣ Затем отправьте *стилевое* изображение\n",
        "\n",
        "💡 Можно отправить оба изображения одним сообщением!\n",
        "\"\"\",\n",
        "        \"content_received\": \"✅ Контентное изображение получено! Теперь отправьте стилевое.\",\n",
        "        \"style_received\": \"✅ Стилевое изображение получено! Начинаю перенос стиля...\",\n",
        "        \"processing\": \"🔄 Выполняю перенос стиля...\",\n",
        "        \"success\": \"🎨 Готово! Перенос стиля выполнен.\",\n",
        "        \"error\": \"⚠️ Произошла ошибка при обработке. Пожалуйста, попробуйте ещё раз.\",\n",
        "        \"mode_not_selected\": \"❌ Сначала выберите режим переноса стиля.\",\n",
        "        \"invalid_option\": \"❌ Пожалуйста, выберите один из доступных вариантов.\",\n",
        "        \"alpha_prompt\": \"🔧 Пожалуйста, введите значение alpha (от 0 до 1):\",\n",
        "        \"alpha_set\": \"✅ Значение alpha установлено на {alpha}.\",\n",
        "        \"alpha_invalid\": \"❌ Неверное значение. Введите число от 0 до 1.\",\n",
        "        \"language_prompt\": \"🌍 Пожалуйста, выберите язык:\",\n",
        "        \"language_set\": \"✅ Язык установлен на русский.\",\n",
        "        \"language_invalid\": \"❌ Неверный выбор, пожалуйста, выберите язык с клавиатуры.\",\n",
        "        \"choose_style_prompt\": \"🖼️ Пожалуйста, выберите стиль из списка ниже:\",\n",
        "        \"style_selected\": \"🎨 Стиль {style} выбран! Теперь отправьте фото для переноса стиля.\",\n",
        "        \"choose_option\": \"📋 Выберите опцию из списка.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "def get_message(key, lang='en'):\n",
        "    \"\"\"Retrieve a localized message by key and language code.\"\"\"\n",
        "    return MESSAGES.get(lang, {}).get(key, MESSAGES['en'].get(key, \"\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a15e2bfe",
      "metadata": {
        "id": "a15e2bfe"
      },
      "outputs": [],
      "source": [
        "app = None  # Global\n",
        "# Preload user data and models\n",
        "user_data_store = load_user_data()\n",
        "\n",
        "# Constants\n",
        "KEYBOARD_OPTIONS = {\n",
        "    'en': [[\"Style Transfer\", \"Color-Preserving\", \"Select a Style\"],\n",
        "           [\"Set alpha\", \"Language\"]],\n",
        "    'ru': [[\"Перенос стиля\", \"Сохранение цветов\", \"Выбрать готовый стиль\"],\n",
        "           [\"Установить alpha\", \"Язык\"]]\n",
        "}\n",
        "\n",
        "PRE_SAVED_STYLES = {\n",
        "    \"Van Gogh\": \"test_images/style/van_gogh.jpg\",\n",
        "    \"Monet\": \"test_images/style/monet.jpg\",\n",
        "    \"Picasso\": \"test_images/style/picasso.jpg\"\n",
        "}\n",
        "\n",
        "\n",
        "# --- Keyboard Helpers ---\n",
        "\n",
        "def get_language_keyboard():\n",
        "    return ReplyKeyboardMarkup([[\"English\", \"Русский\"]],\n",
        "                               one_time_keyboard=True, resize_keyboard=True)\n",
        "\n",
        "\n",
        "def get_styles_keyboard(lang='en'):\n",
        "    styles = list(PRE_SAVED_STYLES.keys())\n",
        "    keyboard = [styles[i:i+2] for i in range(0, len(styles), 2)]\n",
        "    return ReplyKeyboardMarkup(keyboard, one_time_keyboard=True,\n",
        "                               resize_keyboard=True)\n",
        "\n",
        "\n",
        "def get_keyboard(lang='en'):\n",
        "    return ReplyKeyboardMarkup(\n",
        "        KEYBOARD_OPTIONS.get(lang, KEYBOARD_OPTIONS['en']),\n",
        "        one_time_keyboard=True,\n",
        "        resize_keyboard=True\n",
        "    )\n",
        "\n",
        "# --- Command Handlers ---\n",
        "\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Handles /start command\"\"\"\n",
        "    user_id = str(update.effective_user.id)\n",
        "    settings = get_user_settings(user_data_store, user_id)\n",
        "\n",
        "    lang = settings.get('lang') if settings else (\n",
        "        'ru' if update.effective_user.language_code == 'ru' else 'en'\n",
        "    )\n",
        "\n",
        "    if not settings:\n",
        "        update_user_settings(user_data_store, user_id, {'lang': lang})\n",
        "\n",
        "    context.user_data['lang'] = lang\n",
        "\n",
        "    await update.message.reply_text(\n",
        "        get_message(\"welcome\", lang),\n",
        "        reply_markup=get_keyboard(lang),\n",
        "        parse_mode=\"Markdown\"\n",
        "    )\n",
        "\n",
        "\n",
        "# --- Message Handlers ---\n",
        "\n",
        "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Handles all non-command text messages\"\"\"\n",
        "    user_id = str(update.effective_user.id)\n",
        "    user_data = context.user_data\n",
        "    lang = (user_data.get('lang') or\n",
        "            get_user_settings(user_data_store, user_id).get('lang', 'en'))\n",
        "    user_data['lang'] = lang\n",
        "    text = update.message.text\n",
        "    keyboard = KEYBOARD_OPTIONS.get(lang, KEYBOARD_OPTIONS['en'])\n",
        "\n",
        "    # Alpha input mode\n",
        "    if user_data.get(\"awaiting_alpha\"):\n",
        "        try:\n",
        "            alpha = float(text)\n",
        "            if not (0 <= alpha <= 1):\n",
        "                raise ValueError\n",
        "            user_data[\"awaiting_alpha\"] = False\n",
        "            update_user_settings(user_data_store, user_id, {\"alpha\": alpha})\n",
        "            await update.message.reply_text(get_message(\"alpha_set\", lang).format(alpha=alpha))\n",
        "        except ValueError:\n",
        "            await update.message.reply_text(get_message(\"alpha_invalid\", lang))\n",
        "        return\n",
        "\n",
        "    # Language selection mode\n",
        "    if user_data.get(\"awaiting_language\"):\n",
        "        lang_map = {\n",
        "            \"english\": \"en\", \"английский\": \"en\", \"en\": \"en\",\n",
        "            \"русский\": \"ru\", \"russian\": \"ru\", \"ru\": \"ru\"\n",
        "        }\n",
        "        selected = lang_map.get(text.lower())\n",
        "        if selected:\n",
        "            lang = selected\n",
        "            user_data[\"awaiting_language\"] = False\n",
        "            user_data[\"lang\"] = lang\n",
        "            update_user_settings(user_data_store, user_id, {\"lang\": lang})\n",
        "            await update.message.reply_text(get_message(\"language_set\", lang), reply_markup=get_keyboard(lang))\n",
        "        else:\n",
        "            await update.message.reply_text(get_message(\"language_invalid\", lang), reply_markup=get_language_keyboard())\n",
        "        return\n",
        "\n",
        "    # Main keyboard options\n",
        "    if text == keyboard[0][0]:  # Style Transfer\n",
        "        user_data['mode'] = 'standard'\n",
        "        await update.message.reply_text(get_message(\"standard_instructions\", lang), parse_mode=\"Markdown\")\n",
        "    elif text == keyboard[0][1]:  # Color-Preserving\n",
        "        user_data['mode'] = 'color_preserving'\n",
        "        await update.message.reply_text(get_message(\"standard_instructions\", lang), parse_mode=\"Markdown\")\n",
        "    elif text == keyboard[0][2]:  # Select Style\n",
        "        await update.message.reply_text(get_message(\"choose_style_prompt\", lang),\n",
        "                                        reply_markup=get_styles_keyboard(lang))\n",
        "    elif text in PRE_SAVED_STYLES:  # Pre-saved style selected\n",
        "        user_data['selected_style_path'] = PRE_SAVED_STYLES[text]\n",
        "        user_data['mode'] = 'selected_style'\n",
        "        await update.message.reply_text(get_message(\"style_selected\", lang).format(style=text), parse_mode=\"Markdown\")\n",
        "    elif text == keyboard[1][0]:  # Set alpha\n",
        "        user_data[\"awaiting_alpha\"] = True\n",
        "        await update.message.reply_text(get_message(\"alpha_prompt\", lang))\n",
        "    elif text == keyboard[1][1]:  # Change language\n",
        "        user_data[\"awaiting_language\"] = True\n",
        "        await update.message.reply_text(get_message(\"language_prompt\", lang), reply_markup=get_language_keyboard())\n",
        "    else:\n",
        "        await update.message.reply_text(get_message(\"invalid_option\", lang))\n",
        "\n",
        "\n",
        "async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Handles incoming photo messages\"\"\"\n",
        "    user_data = context.user_data\n",
        "    user_id = str(update.effective_user.id)\n",
        "    lang = user_data.get('lang') or get_user_settings(user_data_store, user_id).get('lang', 'en')\n",
        "    user_data['lang'] = lang\n",
        "\n",
        "    if 'mode' not in user_data:\n",
        "        await update.message.reply_text(get_message(\"mode_not_selected\", lang))\n",
        "        return\n",
        "\n",
        "    photo = await update.message.photo[-1].get_file()\n",
        "    byte_img = await photo.download_as_bytearray()\n",
        "\n",
        "    if 'content_image' not in user_data:\n",
        "        user_data['content_image'] = byte_img\n",
        "        user_data['media_group_id'] = update.message.media_group_id\n",
        "\n",
        "        if user_data.get('mode') == 'selected_style':\n",
        "            try:\n",
        "                with open(user_data['selected_style_path'], 'rb') as f:\n",
        "                    user_data['style_image'] = f.read()\n",
        "                await update.message.reply_text(get_message(\"processing\", lang))\n",
        "                await perform_style_transfer(update, context)\n",
        "                await update.message.reply_text(get_message(\"choose_option\", lang), reply_markup=get_keyboard(lang))\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading style file: {e}\")\n",
        "                await update.message.reply_text(get_message(\"style_not_selected\", lang))\n",
        "        elif not update.message.media_group_id:\n",
        "            await update.message.reply_text(get_message(\"content_received\", lang))\n",
        "    else:\n",
        "        user_data['style_image'] = byte_img\n",
        "        await update.message.reply_text(get_message(\"processing\", lang))\n",
        "        await perform_style_transfer(update, context)\n",
        "        await update.message.reply_text(get_message(\"choose_option\", lang), reply_markup=get_keyboard(lang))\n",
        "\n",
        "\n",
        "# --- Style Transfer Core ---\n",
        "\n",
        "async def perform_style_transfer(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Executes style transfer using the selected mode\"\"\"\n",
        "    user_data = context.user_data\n",
        "    user_id = str(update.effective_user.id)\n",
        "    lang = user_data.get('lang') or get_user_settings(user_data_store, user_id).get('lang', 'en')\n",
        "    user_data['lang'] = lang\n",
        "\n",
        "    try:\n",
        "        preserve_colors = (user_data.get('mode') == 'color_preserving')\n",
        "        alpha = get_user_settings(user_data_store, user_id).get(\"alpha\", 1.0)\n",
        "\n",
        "        # Default to general style net\n",
        "        style_net = context.bot_data['net']\n",
        "\n",
        "        # If user selected a predefined style, use the corresponding model\n",
        "        if user_data.get('mode') == 'selected_style':\n",
        "            selected_path = user_data.get('selected_style_path', '').lower()\n",
        "            if 'picasso' in selected_path:\n",
        "                style_net = context.bot_data.get('net_picasso', style_net)\n",
        "            elif 'van_gogh' in selected_path:\n",
        "                style_net = context.bot_data.get('net_van_gogh', style_net)\n",
        "            elif 'monet' in selected_path:\n",
        "                style_net = context.bot_data.get('net_monet', style_net)\n",
        "\n",
        "        result_image = process_images(\n",
        "            net=style_net,\n",
        "            content_bytes=user_data['content_image'],\n",
        "            style_bytes=user_data['style_image'],\n",
        "            preserve_colors=preserve_colors,\n",
        "            alpha=alpha\n",
        "        )\n",
        "\n",
        "        img_bytes = BytesIO()\n",
        "        result_image.save(img_bytes, format='JPEG')\n",
        "        img_bytes.seek(0)\n",
        "        # Save user images\n",
        "        save_user_images(\n",
        "            user_id=user_id,\n",
        "            content=user_data['content_image'],\n",
        "            style=user_data['style_image'],\n",
        "            output=img_bytes\n",
        "        )\n",
        "        img_bytes.seek(0)\n",
        "        await update.message.reply_photo(\n",
        "            photo=img_bytes,\n",
        "            caption=get_message(\"success\", lang)\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        await update.message.reply_text(get_message(\"error\", lang))\n",
        "    finally:\n",
        "        user_data.pop('content_image', None)\n",
        "        user_data.pop('style_image', None)\n",
        "\n",
        "\n",
        "# --- Entry Point ---\n",
        "\n",
        "async def main():\n",
        "    \"\"\"Starts the Telegram bot\"\"\"\n",
        "    global app\n",
        "    print(\"Initializing style transfer models...\")\n",
        "    net, net_picasso, net_van_gogh, net_monet = init_model()\n",
        "\n",
        "    with open('config.json') as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    app = ApplicationBuilder().token(config['telegram_token']).build()\n",
        "    app.bot_data['net'] = net\n",
        "    app.bot_data['net_picasso'] = net_picasso\n",
        "    app.bot_data['net_van_gogh'] = net_van_gogh\n",
        "    app.bot_data['net_monet'] = net_monet\n",
        "\n",
        "    app.add_handler(CommandHandler(\"start\", start))\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
        "    app.add_handler(MessageHandler(filters.PHOTO, handle_image))\n",
        "\n",
        "    print(\"Bot is running...\")\n",
        "\n",
        "    await app.initialize()\n",
        "    await app.start()\n",
        "    await app.updater.start_polling()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f450ad59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f450ad59",
        "outputId": "bafe22e6-ce4c-40f4-cb50-a26e0865597c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing style transfer models...\n",
            "Using GPU: False\n",
            "GPU name: None\n",
            "Bot is running...\n"
          ]
        }
      ],
      "source": [
        "# To start the bot\n",
        "await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "18ecedfe",
      "metadata": {
        "id": "18ecedfe"
      },
      "outputs": [],
      "source": [
        "# To stop the bot\n",
        "# await app.updater.stop()\n",
        "# await app.stop()\n",
        "# await app.shutdown()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
