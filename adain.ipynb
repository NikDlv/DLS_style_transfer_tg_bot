{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddd0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cece9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adain_utils\n",
    "\n",
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Calculate the channel-wise mean and standard deviation of a feature tensor.\n",
    "\n",
    "    Args:\n",
    "        feat (Tensor): Input tensor\n",
    "        eps (float): Small constant to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        Mean and standard deviation tensors.\n",
    "    \"\"\"\n",
    "    size = feat.size()\n",
    "    assert (len(size) == 4)\n",
    "    N, C = size[:2]\n",
    "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
    "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
    "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
    "    return feat_mean, feat_std\n",
    "\n",
    "\n",
    "def adaptive_instance_normalization(content_feat, style_feat):\n",
    "    \"\"\"\n",
    "    Apply Adaptive Instance Normalization to content features using style features.\n",
    "\n",
    "    Args:\n",
    "        content_feat (Tensor): Content features\n",
    "        style_feat (Tensor): Style features\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Stylized feature tensor of the same shape as content_feat.\n",
    "    \"\"\"\n",
    "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
    "    size = content_feat.size()\n",
    "    style_mean, style_std = calc_mean_std(style_feat)\n",
    "    content_mean, content_std = calc_mean_std(content_feat)\n",
    "\n",
    "    normalized_feat = (content_feat - content_mean.expand(\n",
    "        size)) / content_std.expand(size)\n",
    "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)\n",
    "\n",
    "\n",
    "def _calc_feat_flatten_mean_std(feat):\n",
    "    \"\"\"\n",
    "    Flatten 3D feature map and compute per-channel mean and std.\n",
    "    \"\"\"\n",
    "    assert (feat.size()[0] == 3)\n",
    "    assert (isinstance(feat, torch.FloatTensor))\n",
    "    feat_flatten = feat.view(3, -1)\n",
    "    mean = feat_flatten.mean(dim=-1, keepdim=True)\n",
    "    std = feat_flatten.std(dim=-1, keepdim=True)\n",
    "    return feat_flatten, mean, std\n",
    "\n",
    "\n",
    "def _mat_sqrt(x):\n",
    "    \"\"\"\n",
    "    Compute the matrix square root using SVD.\n",
    "    \"\"\"\n",
    "    U, D, V = torch.svd(x)\n",
    "    return torch.mm(torch.mm(U, D.pow(0.5).diag()), V.t())\n",
    "\n",
    "\n",
    "def coral(source, target):\n",
    "    \"\"\"\n",
    "    Perform CORAL (Correlation Alignment) to match the color distribution of the source to the target.\n",
    "    \"\"\"\n",
    "\n",
    "    source_f, source_f_mean, source_f_std = _calc_feat_flatten_mean_std(source)\n",
    "    source_f_norm = (source_f - source_f_mean.expand_as(\n",
    "        source_f)) / source_f_std.expand_as(source_f)\n",
    "    source_f_cov_eye = \\\n",
    "        torch.mm(source_f_norm, source_f_norm.t()) + torch.eye(3)\n",
    "\n",
    "    target_f, target_f_mean, target_f_std = _calc_feat_flatten_mean_std(target)\n",
    "    target_f_norm = (target_f - target_f_mean.expand_as(\n",
    "        target_f)) / target_f_std.expand_as(target_f)\n",
    "    target_f_cov_eye = \\\n",
    "        torch.mm(target_f_norm, target_f_norm.t()) + torch.eye(3)\n",
    "\n",
    "    source_f_norm_transfer = torch.mm(\n",
    "        _mat_sqrt(target_f_cov_eye),\n",
    "        torch.mm(torch.inverse(_mat_sqrt(source_f_cov_eye)),\n",
    "                 source_f_norm)\n",
    "    )\n",
    "\n",
    "    source_f_transfer = (source_f_norm_transfer *\n",
    "                         target_f_std.expand_as(source_f_norm) +\n",
    "                         target_f_mean.expand_as(source_f_norm))\n",
    "\n",
    "    return source_f_transfer.view(source.size())\n",
    "\n",
    "\n",
    "def style_transfer(vgg, decoder, content, style, alpha):\n",
    "    \"\"\"\n",
    "    Perform neural style transfer using AdaIN.\n",
    "    \"\"\"\n",
    "    assert (0.0 <= alpha <= 1.0)\n",
    "    content_f = vgg(content)\n",
    "    style_f = vgg(style)\n",
    "    feat = adaptive_instance_normalization(content_f, style_f)\n",
    "    feat = feat * alpha + content_f * (1 - alpha)\n",
    "    return decoder(feat)\n",
    "\n",
    "\n",
    "def process_images(net, content_bytes, style_bytes, alpha, preserve_colors=False):\n",
    "    \"\"\"Perform style transfer on image bytes\"\"\"\n",
    "    content = load_image(content_bytes)\n",
    "    style = load_image(style_bytes)\n",
    "\n",
    "    # Apply color preservation if needed\n",
    "    if preserve_colors:\n",
    "        style = coral(style, content)\n",
    "\n",
    "    # Move to device and add batch dimension\n",
    "    device = next(net.parameters()).device\n",
    "    content = content.to(device).unsqueeze(0)\n",
    "    style = style.to(device).unsqueeze(0)\n",
    "\n",
    "    # Perform style transfer\n",
    "    with torch.no_grad():\n",
    "        output = style_transfer(\n",
    "            net.encode,\n",
    "            net.decoder,\n",
    "            content,\n",
    "            style,\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "    # Convert to PIL image\n",
    "    output = output.clamp(0, 1)\n",
    "    return transforms.ToPILImage()(output.squeeze(0).cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26686b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adain_net\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder network used to reconstruct an image from AdaIN features.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 128, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 128, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 64, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 64, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 3, (3, 3)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified VGG-19 encoder used to extract content and style features.\n",
    "    Includes convolutional layers up to relu4_1. Extra layers are present but not used.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, (1, 1)),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(3, 64, (3, 3)),\n",
    "            nn.ReLU(),  # relu1-1\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 64, (3, 3)),\n",
    "            nn.ReLU(),  # relu1-2\n",
    "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 128, (3, 3)),\n",
    "            nn.ReLU(),  # relu2-1\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 128, (3, 3)),\n",
    "            nn.ReLU(),  # relu2-2\n",
    "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 256, (3, 3)),\n",
    "            nn.ReLU(),  # relu3-1\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),  # relu3-2\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),  # relu3-3\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),  # relu3-4\n",
    "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu4-1, this is the last layer used\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu4-2\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu4-3\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu4-4\n",
    "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu5-1\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu5-2\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu5-3\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU()  # relu5-4\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Style transfer network combining a fixed VGG encoder and a trainable decoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Net, self).__init__()\n",
    "        enc_layers = list(encoder.children())\n",
    "        self.enc_1 = nn.Sequential(*enc_layers[:4])  # input -> relu1_1\n",
    "        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n",
    "        self.enc_3 = nn.Sequential(*enc_layers[11:18])  # relu2_1 -> relu3_1\n",
    "        self.enc_4 = nn.Sequential(*enc_layers[18:31])  # relu3_1 -> relu4_1\n",
    "        self.decoder = decoder\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "        # fix the encoder\n",
    "        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4']:\n",
    "            for param in getattr(self, name).parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    # extract relu1_1, relu2_1, relu3_1, relu4_1 from input image\n",
    "    def encode_with_intermediate(self, input):\n",
    "        \"\"\"\n",
    "        Extract intermediate features (relu1_1 to relu4_1) from the input image.\n",
    "\n",
    "        Returns:\n",
    "            List of feature maps at different VGG depths.\n",
    "        \"\"\"\n",
    "        results = [input]\n",
    "        for i in range(4):\n",
    "            func = getattr(self, 'enc_{:d}'.format(i + 1))\n",
    "            results.append(func(results[-1]))\n",
    "        return results[1:]\n",
    "\n",
    "    # extract relu4_1 from input image\n",
    "    def encode(self, input):\n",
    "        \"\"\"\n",
    "        Encode input image to relu4_1 feature map using the VGG encoder.\n",
    "\n",
    "        Returns:\n",
    "            Feature map after relu4_1.\n",
    "        \"\"\"\n",
    "        for i in range(4):\n",
    "            input = getattr(self, 'enc_{:d}'.format(i + 1))(input)\n",
    "        return input\n",
    "\n",
    "    def calc_content_loss(self, input, target):\n",
    "        \"\"\"\n",
    "        Compute content loss as MSE between generated and target feature maps.\n",
    "\n",
    "        Returns:\n",
    "            Scalar content loss.\n",
    "        \"\"\"\n",
    "        assert (input.size() == target.size())\n",
    "        assert (target.requires_grad is False)\n",
    "        return self.mse_loss(input, target)\n",
    "\n",
    "    def calc_style_loss(self, input, target):\n",
    "        \"\"\"\n",
    "        Compute style loss as the sum of MSE between mean and std of input and target.\n",
    "\n",
    "        Returns:\n",
    "            Scalar style loss.\n",
    "        \"\"\"\n",
    "        assert (input.size() == target.size())\n",
    "        assert (target.requires_grad is False)\n",
    "        input_mean, input_std = calc_mean_std(input)\n",
    "        target_mean, target_std = calc_mean_std(target)\n",
    "        return (self.mse_loss(input_mean, target_mean) +\n",
    "                self.mse_loss(input_std, target_std))\n",
    "\n",
    "    def forward(self, content, style, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Perform forward pass of the style transfer network.\n",
    "\n",
    "        Args:\n",
    "            content: content image tensor\n",
    "            style: style image tensor\n",
    "            alpha: interpolation factor between content and style features (0 to 1)\n",
    "\n",
    "        Returns:\n",
    "            Content loss and total style loss\n",
    "        \"\"\"\n",
    "        assert 0 <= alpha <= 1\n",
    "        style_feats = self.encode_with_intermediate(style)\n",
    "        content_feat = self.encode(content)\n",
    "        t = adaptive_instance_normalization(content_feat, style_feats[-1])\n",
    "        t = alpha * t + (1 - alpha) * content_feat\n",
    "\n",
    "        g_t = self.decoder(t)\n",
    "        g_t_feats = self.encode_with_intermediate(g_t)\n",
    "\n",
    "        loss_c = self.calc_content_loss(g_t_feats[-1], t)\n",
    "        loss_s = self.calc_style_loss(g_t_feats[0], style_feats[0])\n",
    "        for i in range(1, 4):\n",
    "            loss_s += self.calc_style_loss(g_t_feats[i], style_feats[i])\n",
    "        return loss_c, loss_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_io\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "def load_image(image_bytes):\n",
    "    image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
    "    return transform(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defeea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional\n",
    "def init_model():\n",
    "    \"\"\"Initialize and load style transfer model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using GPU:\", torch.cuda.is_available())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n",
    "    decoder = Decoder()\n",
    "    vgg = VGG()\n",
    "\n",
    "    # Load weights\n",
    "    decoder.model.load_state_dict(torch.load('model_weights/decoder.pth', map_location=device))\n",
    "    vgg.model.load_state_dict(torch.load('model_weights/vgg_normalised.pth', map_location=device))\n",
    "\n",
    "    # Configure models\n",
    "    vgg = nn.Sequential(*list(vgg.model.children())[:31])\n",
    "    vgg.to(device).eval()\n",
    "    decoder.to(device).eval()\n",
    "\n",
    "    decoder_picasso = Decoder()\n",
    "    decoder_van_gogh = Decoder()\n",
    "    decoder_monet = Decoder()\n",
    "\n",
    "    # Load weights for fine-tuned models\n",
    "    decoder_picasso.load_state_dict(torch.load('model_weights/decoder_picasso.pth', map_location=device))\n",
    "    decoder_van_gogh.load_state_dict(torch.load('model_weights/decoder_van_gogh.pth', map_location=device))\n",
    "    decoder_monet.load_state_dict(torch.load('model_weights/decoder_monet.pth', map_location=device))\n",
    "\n",
    "    decoder_picasso.to(device).eval()\n",
    "    decoder_van_gogh.to(device).eval()\n",
    "    decoder_monet.to(device).eval()\n",
    "\n",
    "    return (Net(vgg, decoder).to(device).eval(), Net(vgg, decoder_picasso).to(device).eval(),\n",
    "            Net(vgg, decoder_van_gogh).to(device).eval(), Net(vgg, decoder_monet).to(device).eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fdff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_storage\n",
    "USER_DATA_FILE = \"user_data/user_preferences.json\"\n",
    "USER_DATA_DIR = 'user_data'\n",
    "\n",
    "\n",
    "def load_user_data():\n",
    "    if os.path.exists(USER_DATA_FILE):\n",
    "        with open(USER_DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "\n",
    "def save_user_data(data):\n",
    "    with open(USER_DATA_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def get_user_settings(user_data, user_id):\n",
    "    return user_data.get(str(user_id), {})\n",
    "\n",
    "\n",
    "def update_user_settings(user_data, user_id, updates: dict):\n",
    "    uid = str(user_id)\n",
    "    if uid not in user_data:\n",
    "        user_data[uid] = {}\n",
    "    user_data[uid].update(updates)\n",
    "    save_user_data(user_data)\n",
    "\n",
    "\n",
    "def save_user_images(user_id: str, content: bytes, style: bytes, output: BytesIO):\n",
    "    \"\"\"\n",
    "    Saves content, style, and output images in a user-specific timestamped folder.\n",
    "    \"\"\"\n",
    "    # Create user directory and timestamped subfolder\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    user_dir = os.path.join(USER_DATA_DIR, user_id, f\"result_{timestamp}\")\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    # Save content image\n",
    "    with open(os.path.join(user_dir, \"content.jpg\"), \"wb\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    # Save style image\n",
    "    with open(os.path.join(user_dir, \"style.jpg\"), \"wb\") as f:\n",
    "        f.write(style)\n",
    "\n",
    "    # Save output image\n",
    "    output_path = os.path.join(user_dir, \"output.jpg\")\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(output.getbuffer())\n",
    "\n",
    "    print(f\"Saved images for user {user_id} in {user_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages\n",
    "MESSAGES = {\n",
    "    \"en\": {\n",
    "        \"welcome\": \"\"\"\n",
    "👋 Welcome to the Fast Style Transfer Bot!\n",
    "\n",
    "✨ Choose one of the image generation options:\n",
    "\n",
    "1️⃣  **Style Transfer** 🎨\n",
    "Apply a style from any image to your content photo while keeping the original composition.\n",
    "\n",
    "2️⃣  **Color-Preserving** 🌈\n",
    "Keep your original photo's colors while applying the style's textures and patterns.\n",
    "\n",
    "3️⃣  **Select a Style** 🖼️\n",
    "Select a famous painting style (Van Gogh, Monet, Picasso) and apply it to your photo.\n",
    "\n",
    "⚙️ You can also adjust the strength of the style transfer using the **\"Set alpha\"** command.\n",
    "Choose a value between 0 and 1 — higher values mean stronger stylization.\n",
    "\n",
    "🌐 To change the bot's language, use the **\"Language\"** command and select your preferred language.\n",
    "\"\"\",\n",
    "        \"standard_instructions\": \"\"\"\n",
    "📌 Please follow these steps:\n",
    "\n",
    "1️⃣ Send the *content* image first\n",
    "2️⃣ Then send the *style* image\n",
    "\n",
    "💡 You can also send both images in one message!\n",
    "\"\"\",\n",
    "        \"content_received\": \"✅ Content image received! Now send the style image.\",\n",
    "        \"style_received\": \"✅ Style image received! Starting style transfer...\",\n",
    "        \"processing\": \"🔄 Performing style transfer...\",\n",
    "        \"success\": \"🎨 Style transfer complete!\",\n",
    "        \"error\": \"⚠️ An error occurred during processing. Please try again.\",\n",
    "        \"mode_not_selected\": \"❌ Please first select a style transfer mode from the menu.\",\n",
    "        \"invalid_option\": \"❌ Please choose one of the available options.\",\n",
    "        \"alpha_prompt\": \"🔧 Please enter a value for alpha (between 0 and 1):\",\n",
    "        \"alpha_set\": \"✅ Alpha set to {alpha}.\",\n",
    "        \"alpha_invalid\": \"❌ Invalid value. Please enter a number between 0 and 1.\",\n",
    "        \"language_prompt\": \"🌍 Please choose your language:\",\n",
    "        \"language_set\": \"✅ Language set to English.\",\n",
    "        \"language_invalid\": \"❌ Invalid choice, please select a language from the keyboard.\",\n",
    "        \"choose_style_prompt\": \"🖼️ Please select a style from the list below:\",\n",
    "        \"style_selected\": \"🎨 Style {style} selected! Now please send the content image.\",\n",
    "        \"choose_option\": \"📋 Please select an option from the menu.\"\n",
    "    },\n",
    "\n",
    "    \"ru\": {\n",
    "        \"welcome\": \"\"\"\n",
    "👋 Добро пожаловать в бота для переноса стиля!\n",
    "\n",
    "✨ Выберите один из вариантов:\n",
    "\n",
    "1️⃣  **Перенос стиля** 🎨\n",
    "Примените стиль из любого изображения к вашему фото, сохранив оригинальную композицию.\n",
    "\n",
    "2️⃣  **Сохранение цветов** 🌈\n",
    "Сохраните оригинальные цвета вашего фото, применяя только текстуры и паттерны стиля.\n",
    "\n",
    "3️⃣  **Выбрать готовый стиль** 🖼️\n",
    "Выберите стиль известного художника (Ван Гог, Моне, Пикассо) и примените его к своей фотографии.\n",
    "\n",
    "⚙️ Вы также можете настроить силу переноса стиля с помощью команды **\"Установить alpha\"**.\n",
    "Укажите значение от 0 до 1 — чем больше значение, тем сильнее эффект стилизации.\n",
    "\n",
    "🌐 Чтобы изменить язык бота, используйте команду **\"Язык\"** и выберите предпочитаемый язык.\n",
    "\"\"\",\n",
    "        \"standard_instructions\": \"\"\"\n",
    "📌 Инструкция:\n",
    "\n",
    "1️⃣ Сначала отправьте *контентное* изображение\n",
    "2️⃣ Затем отправьте *стилевое* изображение\n",
    "\n",
    "💡 Можно отправить оба изображения одним сообщением!\n",
    "\"\"\",\n",
    "        \"content_received\": \"✅ Контентное изображение получено! Теперь отправьте стилевое.\",\n",
    "        \"style_received\": \"✅ Стилевое изображение получено! Начинаю перенос стиля...\",\n",
    "        \"processing\": \"🔄 Выполняю перенос стиля...\",\n",
    "        \"success\": \"🎨 Готово! Перенос стиля выполнен.\",\n",
    "        \"error\": \"⚠️ Произошла ошибка при обработке. Пожалуйста, попробуйте ещё раз.\",\n",
    "        \"mode_not_selected\": \"❌ Сначала выберите режим переноса стиля.\",\n",
    "        \"invalid_option\": \"❌ Пожалуйста, выберите один из доступных вариантов.\",\n",
    "        \"alpha_prompt\": \"🔧 Пожалуйста, введите значение alpha (от 0 до 1):\",\n",
    "        \"alpha_set\": \"✅ Значение alpha установлено на {alpha}.\",\n",
    "        \"alpha_invalid\": \"❌ Неверное значение. Введите число от 0 до 1.\",\n",
    "        \"language_prompt\": \"🌍 Пожалуйста, выберите язык:\",\n",
    "        \"language_set\": \"✅ Язык установлен на русский.\",\n",
    "        \"language_invalid\": \"❌ Неверный выбор, пожалуйста, выберите язык с клавиатуры.\",\n",
    "        \"choose_style_prompt\": \"🖼️ Пожалуйста, выберите стиль из списка ниже:\",\n",
    "        \"style_selected\": \"🎨 Стиль {style} выбран! Теперь отправьте фото для переноса стиля.\",\n",
    "        \"choose_option\": \"📋 Выберите опцию из списка.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def get_message(key, lang='en'):\n",
    "    \"\"\"Retrieve a localized message by key and language code.\"\"\"\n",
    "    return MESSAGES.get(lang, {}).get(key, MESSAGES['en'].get(key, \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f03829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bot\n",
    "app = None  # Global\n",
    "# Preload user data and models\n",
    "user_data_store = load_user_data()\n",
    "\n",
    "# Constants\n",
    "KEYBOARD_OPTIONS = {\n",
    "    'en': [[\"Style Transfer\", \"Color-Preserving\", \"Select a Style\"],\n",
    "           [\"Set alpha\", \"Language\"]],\n",
    "    'ru': [[\"Перенос стиля\", \"Сохранение цветов\", \"Выбрать готовый стиль\"],\n",
    "           [\"Установить alpha\", \"Язык\"]]\n",
    "}\n",
    "\n",
    "PRE_SAVED_STYLES = {\n",
    "    \"Van Gogh\": \"test_images/style/van_gogh.jpg\",\n",
    "    \"Monet\": \"test_images/style/monet.jpg\",\n",
    "    \"Picasso\": \"test_images/style/picasso.jpg\"\n",
    "}\n",
    "\n",
    "\n",
    "# --- Keyboard Helpers ---\n",
    "\n",
    "def get_language_keyboard():\n",
    "    return ReplyKeyboardMarkup([[\"English\", \"Русский\"]],\n",
    "                               one_time_keyboard=True, resize_keyboard=True)\n",
    "\n",
    "\n",
    "def get_styles_keyboard(lang='en'):\n",
    "    styles = list(PRE_SAVED_STYLES.keys())\n",
    "    keyboard = [styles[i:i+2] for i in range(0, len(styles), 2)]\n",
    "    return ReplyKeyboardMarkup(keyboard, one_time_keyboard=True,\n",
    "                               resize_keyboard=True)\n",
    "\n",
    "\n",
    "def get_keyboard(lang='en'):\n",
    "    return ReplyKeyboardMarkup(\n",
    "        KEYBOARD_OPTIONS.get(lang, KEYBOARD_OPTIONS['en']),\n",
    "        one_time_keyboard=True,\n",
    "        resize_keyboard=True\n",
    "    )\n",
    "\n",
    "# --- Command Handlers ---\n",
    "\n",
    "\n",
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    \"\"\"Handles /start command\"\"\"\n",
    "    user_id = str(update.effective_user.id)\n",
    "    settings = get_user_settings(user_data_store, user_id)\n",
    "\n",
    "    lang = settings.get('lang') if settings else (\n",
    "        'ru' if update.effective_user.language_code == 'ru' else 'en'\n",
    "    )\n",
    "\n",
    "    if not settings:\n",
    "        update_user_settings(user_data_store, user_id, {'lang': lang})\n",
    "\n",
    "    context.user_data['lang'] = lang\n",
    "\n",
    "    await update.message.reply_text(\n",
    "        get_message(\"welcome\", lang),\n",
    "        reply_markup=get_keyboard(lang),\n",
    "        parse_mode=\"Markdown\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Message Handlers ---\n",
    "\n",
    "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    \"\"\"Handles all non-command text messages\"\"\"\n",
    "    user_id = str(update.effective_user.id)\n",
    "    user_data = context.user_data\n",
    "    lang = (user_data.get('lang') or\n",
    "            get_user_settings(user_data_store, user_id).get('lang', 'en'))\n",
    "    user_data['lang'] = lang\n",
    "    text = update.message.text\n",
    "    keyboard = KEYBOARD_OPTIONS.get(lang, KEYBOARD_OPTIONS['en'])\n",
    "\n",
    "    # Alpha input mode\n",
    "    if user_data.get(\"awaiting_alpha\"):\n",
    "        try:\n",
    "            alpha = float(text)\n",
    "            if not (0 <= alpha <= 1):\n",
    "                raise ValueError\n",
    "            user_data[\"awaiting_alpha\"] = False\n",
    "            update_user_settings(user_data_store, user_id, {\"alpha\": alpha})\n",
    "            await update.message.reply_text(get_message(\"alpha_set\", lang).format(alpha=alpha))\n",
    "        except ValueError:\n",
    "            await update.message.reply_text(get_message(\"alpha_invalid\", lang))\n",
    "        return\n",
    "\n",
    "    # Language selection mode\n",
    "    if user_data.get(\"awaiting_language\"):\n",
    "        lang_map = {\n",
    "            \"english\": \"en\", \"английский\": \"en\", \"en\": \"en\",\n",
    "            \"русский\": \"ru\", \"russian\": \"ru\", \"ru\": \"ru\"\n",
    "        }\n",
    "        selected = lang_map.get(text.lower())\n",
    "        if selected:\n",
    "            lang = selected\n",
    "            user_data[\"awaiting_language\"] = False\n",
    "            user_data[\"lang\"] = lang\n",
    "            update_user_settings(user_data_store, user_id, {\"lang\": lang})\n",
    "            await update.message.reply_text(get_message(\"language_set\", lang), reply_markup=get_keyboard(lang))\n",
    "        else:\n",
    "            await update.message.reply_text(get_message(\"language_invalid\", lang), reply_markup=get_language_keyboard())\n",
    "        return\n",
    "\n",
    "    # Main keyboard options\n",
    "    if text == keyboard[0][0]:  # Style Transfer\n",
    "        user_data['mode'] = 'standard'\n",
    "        await update.message.reply_text(get_message(\"standard_instructions\", lang), parse_mode=\"Markdown\")\n",
    "    elif text == keyboard[0][1]:  # Color-Preserving\n",
    "        user_data['mode'] = 'color_preserving'\n",
    "        await update.message.reply_text(get_message(\"standard_instructions\", lang), parse_mode=\"Markdown\")\n",
    "    elif text == keyboard[0][2]:  # Select Style\n",
    "        await update.message.reply_text(get_message(\"choose_style_prompt\", lang),\n",
    "                                        reply_markup=get_styles_keyboard(lang))\n",
    "    elif text in PRE_SAVED_STYLES:  # Pre-saved style selected\n",
    "        user_data['selected_style_path'] = PRE_SAVED_STYLES[text]\n",
    "        user_data['mode'] = 'selected_style'\n",
    "        await update.message.reply_text(get_message(\"style_selected\", lang).format(style=text), parse_mode=\"Markdown\")\n",
    "    elif text == keyboard[1][0]:  # Set alpha\n",
    "        user_data[\"awaiting_alpha\"] = True\n",
    "        await update.message.reply_text(get_message(\"alpha_prompt\", lang))\n",
    "    elif text == keyboard[1][1]:  # Change language\n",
    "        user_data[\"awaiting_language\"] = True\n",
    "        await update.message.reply_text(get_message(\"language_prompt\", lang), reply_markup=get_language_keyboard())\n",
    "    else:\n",
    "        await update.message.reply_text(get_message(\"invalid_option\", lang))\n",
    "\n",
    "\n",
    "async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    \"\"\"Handles incoming photo messages\"\"\"\n",
    "    user_data = context.user_data\n",
    "    user_id = str(update.effective_user.id)\n",
    "    lang = user_data.get('lang') or get_user_settings(user_data_store, user_id).get('lang', 'en')\n",
    "    user_data['lang'] = lang\n",
    "\n",
    "    if 'mode' not in user_data:\n",
    "        await update.message.reply_text(get_message(\"mode_not_selected\", lang))\n",
    "        return\n",
    "\n",
    "    photo = await update.message.photo[-1].get_file()\n",
    "    byte_img = await photo.download_as_bytearray()\n",
    "\n",
    "    if 'content_image' not in user_data:\n",
    "        user_data['content_image'] = byte_img\n",
    "        user_data['media_group_id'] = update.message.media_group_id\n",
    "\n",
    "        if user_data.get('mode') == 'selected_style':\n",
    "            try:\n",
    "                with open(user_data['selected_style_path'], 'rb') as f:\n",
    "                    user_data['style_image'] = f.read()\n",
    "                await update.message.reply_text(get_message(\"processing\", lang))\n",
    "                await perform_style_transfer(update, context)\n",
    "                await update.message.reply_text(get_message(\"choose_option\", lang), reply_markup=get_keyboard(lang))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading style file: {e}\")\n",
    "                await update.message.reply_text(get_message(\"style_not_selected\", lang))\n",
    "        elif not update.message.media_group_id:\n",
    "            await update.message.reply_text(get_message(\"content_received\", lang))\n",
    "    else:\n",
    "        user_data['style_image'] = byte_img\n",
    "        await update.message.reply_text(get_message(\"processing\", lang))\n",
    "        await perform_style_transfer(update, context)\n",
    "        await update.message.reply_text(get_message(\"choose_option\", lang), reply_markup=get_keyboard(lang))\n",
    "\n",
    "\n",
    "# --- Style Transfer Core ---\n",
    "\n",
    "async def perform_style_transfer(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    \"\"\"Executes style transfer using the selected mode\"\"\"\n",
    "    user_data = context.user_data\n",
    "    user_id = str(update.effective_user.id)\n",
    "    lang = user_data.get('lang') or get_user_settings(user_data_store, user_id).get('lang', 'en')\n",
    "    user_data['lang'] = lang\n",
    "\n",
    "    try:\n",
    "        preserve_colors = (user_data.get('mode') == 'color_preserving')\n",
    "        alpha = get_user_settings(user_data_store, user_id).get(\"alpha\", 1.0)\n",
    "\n",
    "        # Default to general style net\n",
    "        style_net = context.bot_data['net']\n",
    "\n",
    "        # If user selected a predefined style, use the corresponding model\n",
    "        if user_data.get('mode') == 'selected_style':\n",
    "            selected_path = user_data.get('selected_style_path', '').lower()\n",
    "            if 'picasso' in selected_path:\n",
    "                style_net = context.bot_data.get('net_picasso', style_net)\n",
    "            elif 'van_gogh' in selected_path:\n",
    "                style_net = context.bot_data.get('net_van_gogh', style_net)\n",
    "            elif 'monet' in selected_path:\n",
    "                style_net = context.bot_data.get('net_monet', style_net)\n",
    "\n",
    "        result_image = process_images(\n",
    "            net=style_net,\n",
    "            content_bytes=user_data['content_image'],\n",
    "            style_bytes=user_data['style_image'],\n",
    "            preserve_colors=preserve_colors,\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "        img_bytes = BytesIO()\n",
    "        result_image.save(img_bytes, format='JPEG')\n",
    "        img_bytes.seek(0)\n",
    "        # Save user images\n",
    "        save_user_images(\n",
    "            user_id=user_id,\n",
    "            content=user_data['content_image'],\n",
    "            style=user_data['style_image'],\n",
    "            output=img_bytes\n",
    "        )\n",
    "        img_bytes.seek(0)\n",
    "        await update.message.reply_photo(\n",
    "            photo=img_bytes,\n",
    "            caption=get_message(\"success\", lang)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        await update.message.reply_text(get_message(\"error\", lang))\n",
    "    finally:\n",
    "        user_data.pop('content_image', None)\n",
    "        user_data.pop('style_image', None)\n",
    "\n",
    "\n",
    "# --- Entry Point ---\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Starts the Telegram bot\"\"\"\n",
    "    global app\n",
    "    print(\"Initializing style transfer models...\")\n",
    "    net, net_picasso, net_van_gogh, net_monet = init_model()\n",
    "\n",
    "    with open('config.json') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    app = ApplicationBuilder().token(config['telegram_token']).build()\n",
    "    app.bot_data['net'] = net\n",
    "    app.bot_data['net_picasso'] = net_picasso\n",
    "    app.bot_data['net_van_gogh'] = net_van_gogh\n",
    "    app.bot_data['net_monet'] = net_monet\n",
    "\n",
    "    app.add_handler(CommandHandler(\"start\", start))\n",
    "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "    app.add_handler(MessageHandler(filters.PHOTO, handle_image))\n",
    "\n",
    "    print(\"Bot is running...\")\n",
    "    # app.run_polling()\n",
    "    # Jupiter friendly\n",
    "    await app.initialize()\n",
    "    await app.start()\n",
    "    await app.updater.start_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start the bot\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82da833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop the bot\n",
    "await app.updater.stop()\n",
    "await app.stop()\n",
    "await app.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
