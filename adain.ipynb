{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddd0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cece9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adain_utils\n",
    "\n",
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Calculate the channel-wise mean and standard deviation of a feature tensor.\n",
    "\n",
    "    Args:\n",
    "        feat (Tensor): Input tensor\n",
    "        eps (float): Small constant to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        Mean and standard deviation tensors.\n",
    "    \"\"\"\n",
    "    size = feat.size()\n",
    "    assert (len(size) == 4)\n",
    "    N, C = size[:2]\n",
    "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
    "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
    "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
    "    return feat_mean, feat_std\n",
    "\n",
    "\n",
    "def adaptive_instance_normalization(content_feat, style_feat):\n",
    "    \"\"\"\n",
    "    Apply Adaptive Instance Normalization to content features using style features.\n",
    "\n",
    "    Args:\n",
    "        content_feat (Tensor): Content features\n",
    "        style_feat (Tensor): Style features\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Stylized feature tensor of the same shape as content_feat.\n",
    "    \"\"\"\n",
    "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
    "    size = content_feat.size()\n",
    "    style_mean, style_std = calc_mean_std(style_feat)\n",
    "    content_mean, content_std = calc_mean_std(content_feat)\n",
    "\n",
    "    normalized_feat = (content_feat - content_mean.expand(\n",
    "        size)) / content_std.expand(size)\n",
    "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)\n",
    "\n",
    "\n",
    "def _calc_feat_flatten_mean_std(feat):\n",
    "    \"\"\"\n",
    "    Flatten 3D feature map and compute per-channel mean and std.\n",
    "    \"\"\"\n",
    "    assert (feat.size()[0] == 3)\n",
    "    assert (isinstance(feat, torch.FloatTensor))\n",
    "    feat_flatten = feat.view(3, -1)\n",
    "    mean = feat_flatten.mean(dim=-1, keepdim=True)\n",
    "    std = feat_flatten.std(dim=-1, keepdim=True)\n",
    "    return feat_flatten, mean, std\n",
    "\n",
    "\n",
    "def _mat_sqrt(x):\n",
    "    \"\"\"\n",
    "    Compute the matrix square root using SVD.\n",
    "    \"\"\"\n",
    "    U, D, V = torch.svd(x)\n",
    "    return torch.mm(torch.mm(U, D.pow(0.5).diag()), V.t())\n",
    "\n",
    "\n",
    "def coral(source, target):\n",
    "    \"\"\"\n",
    "    Perform CORAL (Correlation Alignment) to match the color distribution of the source to the target.\n",
    "    \"\"\"\n",
    "\n",
    "    source_f, source_f_mean, source_f_std = _calc_feat_flatten_mean_std(source)\n",
    "    source_f_norm = (source_f - source_f_mean.expand_as(\n",
    "        source_f)) / source_f_std.expand_as(source_f)\n",
    "    source_f_cov_eye = \\\n",
    "        torch.mm(source_f_norm, source_f_norm.t()) + torch.eye(3)\n",
    "\n",
    "    target_f, target_f_mean, target_f_std = _calc_feat_flatten_mean_std(target)\n",
    "    target_f_norm = (target_f - target_f_mean.expand_as(\n",
    "        target_f)) / target_f_std.expand_as(target_f)\n",
    "    target_f_cov_eye = \\\n",
    "        torch.mm(target_f_norm, target_f_norm.t()) + torch.eye(3)\n",
    "\n",
    "    source_f_norm_transfer = torch.mm(\n",
    "        _mat_sqrt(target_f_cov_eye),\n",
    "        torch.mm(torch.inverse(_mat_sqrt(source_f_cov_eye)),\n",
    "                 source_f_norm)\n",
    "    )\n",
    "\n",
    "    source_f_transfer = (source_f_norm_transfer *\n",
    "                         target_f_std.expand_as(source_f_norm) +\n",
    "                         target_f_mean.expand_as(source_f_norm))\n",
    "\n",
    "    return source_f_transfer.view(source.size())\n",
    "\n",
    "\n",
    "def style_transfer(vgg, decoder, content, style, alpha):\n",
    "    \"\"\"\n",
    "    Perform neural style transfer using AdaIN.\n",
    "    \"\"\"\n",
    "    assert (0.0 <= alpha <= 1.0)\n",
    "    content_f = vgg(content)\n",
    "    style_f = vgg(style)\n",
    "    feat = adaptive_instance_normalization(content_f, style_f)\n",
    "    feat = feat * alpha + content_f * (1 - alpha)\n",
    "    return decoder(feat)\n",
    "\n",
    "\n",
    "def process_images(net, content_bytes, style_bytes, alpha, preserve_colors=False):\n",
    "    \"\"\"Perform style transfer on image bytes\"\"\"\n",
    "    content = load_image(content_bytes)\n",
    "    style = load_image(style_bytes)\n",
    "\n",
    "    # Apply color preservation if needed\n",
    "    if preserve_colors:\n",
    "        style = coral(style, content)\n",
    "\n",
    "    # Move to device and add batch dimension\n",
    "    device = next(net.parameters()).device\n",
    "    content = content.to(device).unsqueeze(0)\n",
    "    style = style.to(device).unsqueeze(0)\n",
    "\n",
    "    # Perform style transfer\n",
    "    with torch.no_grad():\n",
    "        output = style_transfer(\n",
    "            net.encode,\n",
    "            net.decoder,\n",
    "            content,\n",
    "            style,\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "    # Convert to PIL image\n",
    "    output = output.clamp(0, 1)\n",
    "    return transforms.ToPILImage()(output.squeeze(0).cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26686b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adain_net\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder network used to reconstruct an image from AdaIN features.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 128, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 128, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 64, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 64, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 3, (3, 3)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified VGG-19 encoder used to extract content and style features.\n",
    "    Includes convolutional layers up to relu4_1. Extra layers are present but not used.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, (1, 1)),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(3, 64, (3, 3)),\n",
    "            nn.ReLU(),  # relu1-1\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 64, (3, 3)),\n",
    "            nn.ReLU(),  # relu1-2\n",
    "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 128, (3, 3)),\n",
    "            nn.ReLU(),  # relu2-1\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 128, (3, 3)),\n",
    "            nn.ReLU(),  # relu2-2\n",
    "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 256, (3, 3)),\n",
    "            nn.ReLU(),  # relu3-1\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),  # relu3-2\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),  # relu3-3\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),  # relu3-4\n",
    "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu4-1, this is the last layer used\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu4-2\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu4-3\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu4-4\n",
    "            nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu5-1\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu5-2\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU(),  # relu5-3\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 512, (3, 3)),\n",
    "            nn.ReLU()  # relu5-4\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Style transfer network combining a fixed VGG encoder and a trainable decoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Net, self).__init__()\n",
    "        enc_layers = list(encoder.children())\n",
    "        self.enc_1 = nn.Sequential(*enc_layers[:4])  # input -> relu1_1\n",
    "        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n",
    "        self.enc_3 = nn.Sequential(*enc_layers[11:18])  # relu2_1 -> relu3_1\n",
    "        self.enc_4 = nn.Sequential(*enc_layers[18:31])  # relu3_1 -> relu4_1\n",
    "        self.decoder = decoder\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "        # fix the encoder\n",
    "        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4']:\n",
    "            for param in getattr(self, name).parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    # extract relu1_1, relu2_1, relu3_1, relu4_1 from input image\n",
    "    def encode_with_intermediate(self, input):\n",
    "        \"\"\"\n",
    "        Extract intermediate features (relu1_1 to relu4_1) from the input image.\n",
    "\n",
    "        Returns:\n",
    "            List of feature maps at different VGG depths.\n",
    "        \"\"\"\n",
    "        results = [input]\n",
    "        for i in range(4):\n",
    "            func = getattr(self, 'enc_{:d}'.format(i + 1))\n",
    "            results.append(func(results[-1]))\n",
    "        return results[1:]\n",
    "\n",
    "    # extract relu4_1 from input image\n",
    "    def encode(self, input):\n",
    "        \"\"\"\n",
    "        Encode input image to relu4_1 feature map using the VGG encoder.\n",
    "\n",
    "        Returns:\n",
    "            Feature map after relu4_1.\n",
    "        \"\"\"\n",
    "        for i in range(4):\n",
    "            input = getattr(self, 'enc_{:d}'.format(i + 1))(input)\n",
    "        return input\n",
    "\n",
    "    def calc_content_loss(self, input, target):\n",
    "        \"\"\"\n",
    "        Compute content loss as MSE between generated and target feature maps.\n",
    "\n",
    "        Returns:\n",
    "            Scalar content loss.\n",
    "        \"\"\"\n",
    "        assert (input.size() == target.size())\n",
    "        assert (target.requires_grad is False)\n",
    "        return self.mse_loss(input, target)\n",
    "\n",
    "    def calc_style_loss(self, input, target):\n",
    "        \"\"\"\n",
    "        Compute style loss as the sum of MSE between mean and std of input and target.\n",
    "\n",
    "        Returns:\n",
    "            Scalar style loss.\n",
    "        \"\"\"\n",
    "        assert (input.size() == target.size())\n",
    "        assert (target.requires_grad is False)\n",
    "        input_mean, input_std = calc_mean_std(input)\n",
    "        target_mean, target_std = calc_mean_std(target)\n",
    "        return (self.mse_loss(input_mean, target_mean) +\n",
    "                self.mse_loss(input_std, target_std))\n",
    "\n",
    "    def forward(self, content, style, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Perform forward pass of the style transfer network.\n",
    "\n",
    "        Args:\n",
    "            content: content image tensor\n",
    "            style: style image tensor\n",
    "            alpha: interpolation factor between content and style features (0 to 1)\n",
    "\n",
    "        Returns:\n",
    "            Content loss and total style loss\n",
    "        \"\"\"\n",
    "        assert 0 <= alpha <= 1\n",
    "        style_feats = self.encode_with_intermediate(style)\n",
    "        content_feat = self.encode(content)\n",
    "        t = adaptive_instance_normalization(content_feat, style_feats[-1])\n",
    "        t = alpha * t + (1 - alpha) * content_feat\n",
    "\n",
    "        g_t = self.decoder(t)\n",
    "        g_t_feats = self.encode_with_intermediate(g_t)\n",
    "\n",
    "        loss_c = self.calc_content_loss(g_t_feats[-1], t)\n",
    "        loss_s = self.calc_style_loss(g_t_feats[0], style_feats[0])\n",
    "        for i in range(1, 4):\n",
    "            loss_s += self.calc_style_loss(g_t_feats[i], style_feats[i])\n",
    "        return loss_c, loss_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_io\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "def load_image(image_bytes):\n",
    "    image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
    "    return transform(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defeea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional\n",
    "def init_model():\n",
    "    \"\"\"Initialize and load style transfer model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using GPU:\", torch.cuda.is_available())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n",
    "    decoder = Decoder()\n",
    "    vgg = VGG()\n",
    "\n",
    "    # Load weights\n",
    "    decoder.model.load_state_dict(torch.load('model_weights/decoder.pth', map_location=device))\n",
    "    vgg.model.load_state_dict(torch.load('model_weights/vgg_normalised.pth', map_location=device))\n",
    "\n",
    "    # Configure models\n",
    "    vgg = nn.Sequential(*list(vgg.model.children())[:31])\n",
    "    vgg.to(device).eval()\n",
    "    decoder.to(device).eval()\n",
    "\n",
    "    decoder_picasso = Decoder()\n",
    "    decoder_van_gogh = Decoder()\n",
    "    decoder_monet = Decoder()\n",
    "\n",
    "    # Load weights for fine-tuned models\n",
    "    decoder_picasso.load_state_dict(torch.load('model_weights/decoder_picasso.pth', map_location=device))\n",
    "    decoder_van_gogh.load_state_dict(torch.load('model_weights/decoder_van_gogh.pth', map_location=device))\n",
    "    decoder_monet.load_state_dict(torch.load('model_weights/decoder_monet.pth', map_location=device))\n",
    "\n",
    "    decoder_picasso.to(device).eval()\n",
    "    decoder_van_gogh.to(device).eval()\n",
    "    decoder_monet.to(device).eval()\n",
    "\n",
    "    return (Net(vgg, decoder).to(device).eval(), Net(vgg, decoder_picasso).to(device).eval(),\n",
    "            Net(vgg, decoder_van_gogh).to(device).eval(), Net(vgg, decoder_monet).to(device).eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fdff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_storage\n",
    "USER_DATA_FILE = \"user_data/user_preferences.json\"\n",
    "USER_DATA_DIR = 'user_data'\n",
    "\n",
    "\n",
    "def load_user_data():\n",
    "    if os.path.exists(USER_DATA_FILE):\n",
    "        with open(USER_DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "\n",
    "def save_user_data(data):\n",
    "    with open(USER_DATA_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def get_user_settings(user_data, user_id):\n",
    "    return user_data.get(str(user_id), {})\n",
    "\n",
    "\n",
    "def update_user_settings(user_data, user_id, updates: dict):\n",
    "    uid = str(user_id)\n",
    "    if uid not in user_data:\n",
    "        user_data[uid] = {}\n",
    "    user_data[uid].update(updates)\n",
    "    save_user_data(user_data)\n",
    "\n",
    "\n",
    "def save_user_images(user_id: str, content: bytes, style: bytes, output: BytesIO):\n",
    "    \"\"\"\n",
    "    Saves content, style, and output images in a user-specific timestamped folder.\n",
    "    \"\"\"\n",
    "    # Create user directory and timestamped subfolder\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    user_dir = os.path.join(USER_DATA_DIR, user_id, f\"result_{timestamp}\")\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    # Save content image\n",
    "    with open(os.path.join(user_dir, \"content.jpg\"), \"wb\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    # Save style image\n",
    "    with open(os.path.join(user_dir, \"style.jpg\"), \"wb\") as f:\n",
    "        f.write(style)\n",
    "\n",
    "    # Save output image\n",
    "    output_path = os.path.join(user_dir, \"output.jpg\")\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(output.getbuffer())\n",
    "\n",
    "    print(f\"Saved images for user {user_id} in {user_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages\n",
    "MESSAGES = {\n",
    "    \"en\": {\n",
    "        \"welcome\": \"\"\"\n",
    "ðŸ‘‹ Welcome to the Fast Style Transfer Bot!\n",
    "\n",
    "âœ¨ Choose one of the image generation options:\n",
    "\n",
    "1ï¸âƒ£  **Style Transfer** ðŸŽ¨\n",
    "Apply a style from any image to your content photo while keeping the original composition.\n",
    "\n",
    "2ï¸âƒ£  **Color-Preserving** ðŸŒˆ\n",
    "Keep your original photo's colors while applying the style's textures and patterns.\n",
    "\n",
    "3ï¸âƒ£  **Select a Style** ðŸ–¼ï¸\n",
    "Select a famous painting style (Van Gogh, Monet, Picasso) and apply it to your photo.\n",
    "\n",
    "âš™ï¸ You can also adjust the strength of the style transfer using the **\"Set alpha\"** command.\n",
    "Choose a value between 0 and 1 â€” higher values mean stronger stylization.\n",
    "\n",
    "ðŸŒ To change the bot's language, use the **\"Language\"** command and select your preferred language.\n",
    "\"\"\",\n",
    "        \"standard_instructions\": \"\"\"\n",
    "ðŸ“Œ Please follow these steps:\n",
    "\n",
    "1ï¸âƒ£ Send the *content* image first\n",
    "2ï¸âƒ£ Then send the *style* image\n",
    "\n",
    "ðŸ’¡ You can also send both images in one message!\n",
    "\"\"\",\n",
    "        \"content_received\": \"âœ… Content image received! Now send the style image.\",\n",
    "        \"style_received\": \"âœ… Style image received! Starting style transfer...\",\n",
    "        \"processing\": \"ðŸ”„ Performing style transfer...\",\n",
    "        \"success\": \"ðŸŽ¨ Style transfer complete!\",\n",
    "        \"error\": \"âš ï¸ An error occurred during processing. Please try again.\",\n",
    "        \"mode_not_selected\": \"âŒ Please first select a style transfer mode from the menu.\",\n",
    "        \"invalid_option\": \"âŒ Please choose one of the available options.\",\n",
    "        \"alpha_prompt\": \"ðŸ”§ Please enter a value for alpha (between 0 and 1):\",\n",
    "        \"alpha_set\": \"âœ… Alpha set to {alpha}.\",\n",
    "        \"alpha_invalid\": \"âŒ Invalid value. Please enter a number between 0 and 1.\",\n",
    "        \"language_prompt\": \"ðŸŒ Please choose your language:\",\n",
    "        \"language_set\": \"âœ… Language set to English.\",\n",
    "        \"language_invalid\": \"âŒ Invalid choice, please select a language from the keyboard.\",\n",
    "        \"choose_style_prompt\": \"ðŸ–¼ï¸ Please select a style from the list below:\",\n",
    "        \"style_selected\": \"ðŸŽ¨ Style {style} selected! Now please send the content image.\",\n",
    "        \"choose_option\": \"ðŸ“‹ Please select an option from the menu.\"\n",
    "    },\n",
    "\n",
    "    \"ru\": {\n",
    "        \"welcome\": \"\"\"\n",
    "ðŸ‘‹ Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ Ð² Ð±Ð¾Ñ‚Ð° Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ° ÑÑ‚Ð¸Ð»Ñ!\n",
    "\n",
    "âœ¨ Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ð´Ð¸Ð½ Ð¸Ð· Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð²:\n",
    "\n",
    "1ï¸âƒ£  **ÐŸÐµÑ€ÐµÐ½Ð¾Ñ ÑÑ‚Ð¸Ð»Ñ** ðŸŽ¨\n",
    "ÐŸÑ€Ð¸Ð¼ÐµÐ½Ð¸Ñ‚Ðµ ÑÑ‚Ð¸Ð»ÑŒ Ð¸Ð· Ð»ÑŽÐ±Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ðº Ð²Ð°ÑˆÐµÐ¼Ñƒ Ñ„Ð¾Ñ‚Ð¾, ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ð² Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½ÑƒÑŽ ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ.\n",
    "\n",
    "2ï¸âƒ£  **Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ†Ð²ÐµÑ‚Ð¾Ð²** ðŸŒˆ\n",
    "Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚Ðµ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ†Ð²ÐµÑ‚Ð° Ð²Ð°ÑˆÐµÐ³Ð¾ Ñ„Ð¾Ñ‚Ð¾, Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‚ÐµÐºÑÑ‚ÑƒÑ€Ñ‹ Ð¸ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ ÑÑ‚Ð¸Ð»Ñ.\n",
    "\n",
    "3ï¸âƒ£  **Ð’Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ** ðŸ–¼ï¸\n",
    "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÑ‚Ð¸Ð»ÑŒ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾Ð³Ð¾ Ñ…ÑƒÐ´Ð¾Ð¶Ð½Ð¸ÐºÐ° (Ð’Ð°Ð½ Ð“Ð¾Ð³, ÐœÐ¾Ð½Ðµ, ÐŸÐ¸ÐºÐ°ÑÑÐ¾) Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ñ‚Ðµ ÐµÐ³Ð¾ Ðº ÑÐ²Ð¾ÐµÐ¹ Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ð¸.\n",
    "\n",
    "âš™ï¸ Ð’Ñ‹ Ñ‚Ð°ÐºÐ¶Ðµ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ ÑÐ¸Ð»Ñƒ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ° ÑÑ‚Ð¸Ð»Ñ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ **\"Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ alpha\"**.\n",
    "Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¾Ñ‚ 0 Ð´Ð¾ 1 â€” Ñ‡ÐµÐ¼ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ, Ñ‚ÐµÐ¼ ÑÐ¸Ð»ÑŒÐ½ÐµÐµ ÑÑ„Ñ„ÐµÐºÑ‚ ÑÑ‚Ð¸Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸.\n",
    "\n",
    "ðŸŒ Ð§Ñ‚Ð¾Ð±Ñ‹ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ ÑÐ·Ñ‹Ðº Ð±Ð¾Ñ‚Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ **\"Ð¯Ð·Ñ‹Ðº\"** Ð¸ Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ð¹ ÑÐ·Ñ‹Ðº.\n",
    "\"\"\",\n",
    "        \"standard_instructions\": \"\"\"\n",
    "ðŸ“Œ Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ:\n",
    "\n",
    "1ï¸âƒ£ Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ *ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð½Ð¾Ðµ* Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ\n",
    "2ï¸âƒ£ Ð—Ð°Ñ‚ÐµÐ¼ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ *ÑÑ‚Ð¸Ð»ÐµÐ²Ð¾Ðµ* Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ\n",
    "\n",
    "ðŸ’¡ ÐœÐ¾Ð¶Ð½Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð¾Ð±Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¾Ð´Ð½Ð¸Ð¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÐµÐ¼!\n",
    "\"\"\",\n",
    "        \"content_received\": \"âœ… ÐšÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾! Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ ÑÑ‚Ð¸Ð»ÐµÐ²Ð¾Ðµ.\",\n",
    "        \"style_received\": \"âœ… Ð¡Ñ‚Ð¸Ð»ÐµÐ²Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾! ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð¿ÐµÑ€ÐµÐ½Ð¾Ñ ÑÑ‚Ð¸Ð»Ñ...\",\n",
    "        \"processing\": \"ðŸ”„ Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÑŽ Ð¿ÐµÑ€ÐµÐ½Ð¾Ñ ÑÑ‚Ð¸Ð»Ñ...\",\n",
    "        \"success\": \"ðŸŽ¨ Ð“Ð¾Ñ‚Ð¾Ð²Ð¾! ÐŸÐµÑ€ÐµÐ½Ð¾Ñ ÑÑ‚Ð¸Ð»Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½.\",\n",
    "        \"error\": \"âš ï¸ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.\",\n",
    "        \"mode_not_selected\": \"âŒ Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€ÐµÐ¶Ð¸Ð¼ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ° ÑÑ‚Ð¸Ð»Ñ.\",\n",
    "        \"invalid_option\": \"âŒ ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ð´Ð¸Ð½ Ð¸Ð· Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð².\",\n",
    "        \"alpha_prompt\": \"ðŸ”§ ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ alpha (Ð¾Ñ‚ 0 Ð´Ð¾ 1):\",\n",
    "        \"alpha_set\": \"âœ… Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ alpha ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ Ð½Ð° {alpha}.\",\n",
    "        \"alpha_invalid\": \"âŒ ÐÐµÐ²ÐµÑ€Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ. Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ñ‡Ð¸ÑÐ»Ð¾ Ð¾Ñ‚ 0 Ð´Ð¾ 1.\",\n",
    "        \"language_prompt\": \"ðŸŒ ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÐ·Ñ‹Ðº:\",\n",
    "        \"language_set\": \"âœ… Ð¯Ð·Ñ‹Ðº ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¸Ð¹.\",\n",
    "        \"language_invalid\": \"âŒ ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÐ·Ñ‹Ðº Ñ ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ñ‹.\",\n",
    "        \"choose_style_prompt\": \"ðŸ–¼ï¸ ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÑ‚Ð¸Ð»ÑŒ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ° Ð½Ð¸Ð¶Ðµ:\",\n",
    "        \"style_selected\": \"ðŸŽ¨ Ð¡Ñ‚Ð¸Ð»ÑŒ {style} Ð²Ñ‹Ð±Ñ€Ð°Ð½! Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ„Ð¾Ñ‚Ð¾ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ° ÑÑ‚Ð¸Ð»Ñ.\",\n",
    "        \"choose_option\": \"ðŸ“‹ Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ð¿Ñ†Ð¸ÑŽ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ°.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def get_message(key, lang='en'):\n",
    "    \"\"\"Retrieve a localized message by key and language code.\"\"\"\n",
    "    return MESSAGES.get(lang, {}).get(key, MESSAGES['en'].get(key, \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f03829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bot\n",
    "app = None  # Global\n",
    "# Preload user data and models\n",
    "user_data_store = load_user_data()\n",
    "\n",
    "# Constants\n",
    "KEYBOARD_OPTIONS = {\n",
    "    'en': [[\"Style Transfer\", \"Color-Preserving\", \"Select a Style\"],\n",
    "           [\"Set alpha\", \"Language\"]],\n",
    "    'ru': [[\"ÐŸÐµÑ€ÐµÐ½Ð¾Ñ ÑÑ‚Ð¸Ð»Ñ\", \"Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ†Ð²ÐµÑ‚Ð¾Ð²\", \"Ð’Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ\"],\n",
    "           [\"Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ alpha\", \"Ð¯Ð·Ñ‹Ðº\"]]\n",
    "}\n",
    "\n",
    "PRE_SAVED_STYLES = {\n",
    "    \"Van Gogh\": \"test_images/style/van_gogh.jpg\",\n",
    "    \"Monet\": \"test_images/style/monet.jpg\",\n",
    "    \"Picasso\": \"test_images/style/picasso.jpg\"\n",
    "}\n",
    "\n",
    "\n",
    "# --- Keyboard Helpers ---\n",
    "\n",
    "def get_language_keyboard():\n",
    "    return ReplyKeyboardMarkup([[\"English\", \"Ð ÑƒÑÑÐºÐ¸Ð¹\"]],\n",
    "                               one_time_keyboard=True, resize_keyboard=True)\n",
    "\n",
    "\n",
    "def get_styles_keyboard(lang='en'):\n",
    "    styles = list(PRE_SAVED_STYLES.keys())\n",
    "    keyboard = [styles[i:i+2] for i in range(0, len(styles), 2)]\n",
    "    return ReplyKeyboardMarkup(keyboard, one_time_keyboard=True,\n",
    "                               resize_keyboard=True)\n",
    "\n",
    "\n",
    "def get_keyboard(lang='en'):\n",
    "    return ReplyKeyboardMarkup(\n",
    "        KEYBOARD_OPTIONS.get(lang, KEYBOARD_OPTIONS['en']),\n",
    "        one_time_keyboard=True,\n",
    "        resize_keyboard=True\n",
    "    )\n",
    "\n",
    "# --- Command Handlers ---\n",
    "\n",
    "\n",
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    \"\"\"Handles /start command\"\"\"\n",
    "    user_id = str(update.effective_user.id)\n",
    "    settings = get_user_settings(user_data_store, user_id)\n",
    "\n",
    "    lang = settings.get('lang') if settings else (\n",
    "        'ru' if update.effective_user.language_code == 'ru' else 'en'\n",
    "    )\n",
    "\n",
    "    if not settings:\n",
    "        update_user_settings(user_data_store, user_id, {'lang': lang})\n",
    "\n",
    "    context.user_data['lang'] = lang\n",
    "\n",
    "    await update.message.reply_text(\n",
    "        get_message(\"welcome\", lang),\n",
    "        reply_markup=get_keyboard(lang),\n",
    "        parse_mode=\"Markdown\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Message Handlers ---\n",
    "\n",
    "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    \"\"\"Handles all non-command text messages\"\"\"\n",
    "    user_id = str(update.effective_user.id)\n",
    "    user_data = context.user_data\n",
    "    lang = (user_data.get('lang') or\n",
    "            get_user_settings(user_data_store, user_id).get('lang', 'en'))\n",
    "    user_data['lang'] = lang\n",
    "    text = update.message.text\n",
    "    keyboard = KEYBOARD_OPTIONS.get(lang, KEYBOARD_OPTIONS['en'])\n",
    "\n",
    "    # Alpha input mode\n",
    "    if user_data.get(\"awaiting_alpha\"):\n",
    "        try:\n",
    "            alpha = float(text)\n",
    "            if not (0 <= alpha <= 1):\n",
    "                raise ValueError\n",
    "            user_data[\"awaiting_alpha\"] = False\n",
    "            update_user_settings(user_data_store, user_id, {\"alpha\": alpha})\n",
    "            await update.message.reply_text(get_message(\"alpha_set\", lang).format(alpha=alpha))\n",
    "        except ValueError:\n",
    "            await update.message.reply_text(get_message(\"alpha_invalid\", lang))\n",
    "        return\n",
    "\n",
    "    # Language selection mode\n",
    "    if user_data.get(\"awaiting_language\"):\n",
    "        lang_map = {\n",
    "            \"english\": \"en\", \"Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹\": \"en\", \"en\": \"en\",\n",
    "            \"Ñ€ÑƒÑÑÐºÐ¸Ð¹\": \"ru\", \"russian\": \"ru\", \"ru\": \"ru\"\n",
    "        }\n",
    "        selected = lang_map.get(text.lower())\n",
    "        if selected:\n",
    "            lang = selected\n",
    "            user_data[\"awaiting_language\"] = False\n",
    "            user_data[\"lang\"] = lang\n",
    "            update_user_settings(user_data_store, user_id, {\"lang\": lang})\n",
    "            await update.message.reply_text(get_message(\"language_set\", lang), reply_markup=get_keyboard(lang))\n",
    "        else:\n",
    "            await update.message.reply_text(get_message(\"language_invalid\", lang), reply_markup=get_language_keyboard())\n",
    "        return\n",
    "\n",
    "    # Main keyboard options\n",
    "    if text == keyboard[0][0]:  # Style Transfer\n",
    "        user_data['mode'] = 'standard'\n",
    "        await update.message.reply_text(get_message(\"standard_instructions\", lang), parse_mode=\"Markdown\")\n",
    "    elif text == keyboard[0][1]:  # Color-Preserving\n",
    "        user_data['mode'] = 'color_preserving'\n",
    "        await update.message.reply_text(get_message(\"standard_instructions\", lang), parse_mode=\"Markdown\")\n",
    "    elif text == keyboard[0][2]:  # Select Style\n",
    "        await update.message.reply_text(get_message(\"choose_style_prompt\", lang),\n",
    "                                        reply_markup=get_styles_keyboard(lang))\n",
    "    elif text in PRE_SAVED_STYLES:  # Pre-saved style selected\n",
    "        user_data['selected_style_path'] = PRE_SAVED_STYLES[text]\n",
    "        user_data['mode'] = 'selected_style'\n",
    "        await update.message.reply_text(get_message(\"style_selected\", lang).format(style=text), parse_mode=\"Markdown\")\n",
    "    elif text == keyboard[1][0]:  # Set alpha\n",
    "        user_data[\"awaiting_alpha\"] = True\n",
    "        await update.message.reply_text(get_message(\"alpha_prompt\", lang))\n",
    "    elif text == keyboard[1][1]:  # Change language\n",
    "        user_data[\"awaiting_language\"] = True\n",
    "        await update.message.reply_text(get_message(\"language_prompt\", lang), reply_markup=get_language_keyboard())\n",
    "    else:\n",
    "        await update.message.reply_text(get_message(\"invalid_option\", lang))\n",
    "\n",
    "\n",
    "async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    \"\"\"Handles incoming photo messages\"\"\"\n",
    "    user_data = context.user_data\n",
    "    user_id = str(update.effective_user.id)\n",
    "    lang = user_data.get('lang') or get_user_settings(user_data_store, user_id).get('lang', 'en')\n",
    "    user_data['lang'] = lang\n",
    "\n",
    "    if 'mode' not in user_data:\n",
    "        await update.message.reply_text(get_message(\"mode_not_selected\", lang))\n",
    "        return\n",
    "\n",
    "    photo = await update.message.photo[-1].get_file()\n",
    "    byte_img = await photo.download_as_bytearray()\n",
    "\n",
    "    if 'content_image' not in user_data:\n",
    "        user_data['content_image'] = byte_img\n",
    "        user_data['media_group_id'] = update.message.media_group_id\n",
    "\n",
    "        if user_data.get('mode') == 'selected_style':\n",
    "            try:\n",
    "                with open(user_data['selected_style_path'], 'rb') as f:\n",
    "                    user_data['style_image'] = f.read()\n",
    "                await update.message.reply_text(get_message(\"processing\", lang))\n",
    "                await perform_style_transfer(update, context)\n",
    "                await update.message.reply_text(get_message(\"choose_option\", lang), reply_markup=get_keyboard(lang))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading style file: {e}\")\n",
    "                await update.message.reply_text(get_message(\"style_not_selected\", lang))\n",
    "        elif not update.message.media_group_id:\n",
    "            await update.message.reply_text(get_message(\"content_received\", lang))\n",
    "    else:\n",
    "        user_data['style_image'] = byte_img\n",
    "        await update.message.reply_text(get_message(\"processing\", lang))\n",
    "        await perform_style_transfer(update, context)\n",
    "        await update.message.reply_text(get_message(\"choose_option\", lang), reply_markup=get_keyboard(lang))\n",
    "\n",
    "\n",
    "# --- Style Transfer Core ---\n",
    "\n",
    "async def perform_style_transfer(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    \"\"\"Executes style transfer using the selected mode\"\"\"\n",
    "    user_data = context.user_data\n",
    "    user_id = str(update.effective_user.id)\n",
    "    lang = user_data.get('lang') or get_user_settings(user_data_store, user_id).get('lang', 'en')\n",
    "    user_data['lang'] = lang\n",
    "\n",
    "    try:\n",
    "        preserve_colors = (user_data.get('mode') == 'color_preserving')\n",
    "        alpha = get_user_settings(user_data_store, user_id).get(\"alpha\", 1.0)\n",
    "\n",
    "        # Default to general style net\n",
    "        style_net = context.bot_data['net']\n",
    "\n",
    "        # If user selected a predefined style, use the corresponding model\n",
    "        if user_data.get('mode') == 'selected_style':\n",
    "            selected_path = user_data.get('selected_style_path', '').lower()\n",
    "            if 'picasso' in selected_path:\n",
    "                style_net = context.bot_data.get('net_picasso', style_net)\n",
    "            elif 'van_gogh' in selected_path:\n",
    "                style_net = context.bot_data.get('net_van_gogh', style_net)\n",
    "            elif 'monet' in selected_path:\n",
    "                style_net = context.bot_data.get('net_monet', style_net)\n",
    "\n",
    "        result_image = process_images(\n",
    "            net=style_net,\n",
    "            content_bytes=user_data['content_image'],\n",
    "            style_bytes=user_data['style_image'],\n",
    "            preserve_colors=preserve_colors,\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "        img_bytes = BytesIO()\n",
    "        result_image.save(img_bytes, format='JPEG')\n",
    "        img_bytes.seek(0)\n",
    "        # Save user images\n",
    "        save_user_images(\n",
    "            user_id=user_id,\n",
    "            content=user_data['content_image'],\n",
    "            style=user_data['style_image'],\n",
    "            output=img_bytes\n",
    "        )\n",
    "        img_bytes.seek(0)\n",
    "        await update.message.reply_photo(\n",
    "            photo=img_bytes,\n",
    "            caption=get_message(\"success\", lang)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        await update.message.reply_text(get_message(\"error\", lang))\n",
    "    finally:\n",
    "        user_data.pop('content_image', None)\n",
    "        user_data.pop('style_image', None)\n",
    "\n",
    "\n",
    "# --- Entry Point ---\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Starts the Telegram bot\"\"\"\n",
    "    global app\n",
    "    print(\"Initializing style transfer models...\")\n",
    "    net, net_picasso, net_van_gogh, net_monet = init_model()\n",
    "\n",
    "    with open('config.json') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    app = ApplicationBuilder().token(config['telegram_token']).build()\n",
    "    app.bot_data['net'] = net\n",
    "    app.bot_data['net_picasso'] = net_picasso\n",
    "    app.bot_data['net_van_gogh'] = net_van_gogh\n",
    "    app.bot_data['net_monet'] = net_monet\n",
    "\n",
    "    app.add_handler(CommandHandler(\"start\", start))\n",
    "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "    app.add_handler(MessageHandler(filters.PHOTO, handle_image))\n",
    "\n",
    "    print(\"Bot is running...\")\n",
    "    # app.run_polling()\n",
    "    # Jupiter friendly\n",
    "    await app.initialize()\n",
    "    await app.start()\n",
    "    await app.updater.start_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start the bot\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82da833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop the bot\n",
    "await app.updater.stop()\n",
    "await app.stop()\n",
    "await app.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
